{"componentChunkName":"component---src-templates-blog-posts-tsx","path":"/posts/","result":{"data":{"site":{"siteMetadata":{"siteUrl":"https://laniewski.me"}}},"pageContext":{"data":[{"id":"b5bffd9c-b881-59b9-9dd2-4f093bc69ba1","body":"\nBarrel files consolidate the exports of multiple modules into a single file. We use them to import a module using a single import statement without worrying about the underlying folder structure.\n\nHave a look at the following example of a `Modal` component:\n\n```\n/components\n└── /Modal\n    ├── Modal.js\n    ├── ModalHeader.js\n    ├── ModalContent.js\n    └── ModalFooter.js\n```\n\nA barrel would be an `index.js` file at `./components/Modal` with the following definition:\n\n```js\nexport { Modal } from \"./Modal\";\nexport { ModalHeader } from \"./ModalHeader\";\nexport { ModalContent } from \"./ModalContent\";\nexport { ModalFooter } from \"./ModalFooter\";\n```\n\nIt allows us to write a single import statement, such as:\n\n```js\nimport { Modal, ModalHeader, ModalContent, ModalFooter } from \"./Modal\";\n```\n\n…instead of:\n\n```js\nimport { Modal } from \"./Modal/Modal\";\nimport { ModalHeader } from \"./Modal/ModalHeader\";\nimport { ModalContent } from \"./Modal/ModalContent\";\nimport { ModalFooter } from \"./Modal/ModalFooter\";\n```\n\nAt first glance, barrel files look promising! Barrel files can improve code organization and make imports cleaner, especially in larger projects with many modules. But there’s a hidden cost.\n\n## The bundle size cost\n\nIf you target a no-build architecture or don’t have [tree-shaking](/blog/2018-04-29-publishing-packages-to-npm/) enabled in your bundler, all the files imported in the barrel file will get bundled into the application, even when unused! It results in tons of dead code, which can impact loading times.\n\nLet’s have a look at the following application, which renders a simple `Button` component from the [Material Design component library](https://mui.com/material-ui/):\n\n```jsx\nimport { Button } from \"@mui/material\";\n\nexport function App() {\n  return <Button>Text</Button>;\n}\n```\n\n```\n> node scripts/build.js\n\nCreating an optimized production build...\nCompiled successfully.\n\nFile sizes after gzip:\n\n  151.47 kB build/static/js/main.js\n```\n\nNow let’s import the `Button` component directly, skipping the barrel file:\n\n```diff\n-import { Button } from \"@mui/material\";\n+import Button from \"@mui/material/Button\";\n\nexport function App() {\n  return <Button>Text</Button>;\n}\n```\n\n```\n> node scripts/build.js\n\nCreating an optimized production build...\nCompiled successfully.\n\nFile sizes after gzip:\n\n  75.69 kB (-75.77 kB)  build/static/js/main.js\n```\n\n<Alert type=\"success\">\n  When not using a barrel file, the build size <u>decreased from ~151 kB to ~75 kB</u>.\n</Alert>\n\n<Alert type=\"info\">\n  Fortunately, most bundlers have tree shaking enabled by default because it reduces bundle size without changing the code behavior.\n</Alert>\n\n## The build-time cost\n\nBarrel files are one of the key reasons why tooling is slow in bigger projects. All of your modules are likely to load barrel files (the imports are nice, after all), and so are your modules hidden behind the barrel files. It can result in a graph of import statements, where each module depends on another one, and so on.\n\nThe more files, the longer it takes for the bundler to resolve and manage them. Here are the execution times of the build script for both variants:\n\n- **With barrel file:**\n\n```jsx\nimport { Button } from \"@mui/material\";\n\nexport function App() {\n  return <Button>Text</Button>;\n}\n```\n\n```\nExecution time: 0h:00m:10s sec\n```\n\n- **Without barrel file:**\n\n```diff\n-import { Button } from \"@mui/material\";\n+import Button from \"@mui/material/Button\";\n\nexport function App() {\n  return <Button>Text</Button>;\n}\n```\n\n```\nExecution time: 0h:00m:7s sec\n```\n\n<Alert type=\"success\">\n  The build time is <u>30% faster</u> when not using a barrel file.<sup title=\"In a real-world scenario, the build time will probably not decrease by that much.\">*</sup>\n</Alert>\n\n## The test-time cost\n\nIn both articles (I highly recommend reading those):\n\n- [\"Why is My Jest Test Suite So Slow?\"](https://dev.to/twynsicle/why-is-my-jest-test-suite-so-slow-1od) by Steven Lemon, and\n- [\"Speeding up the JavaScript ecosystem - The barrel file debacle\"](https://marvinh.dev/blog/speeding-up-javascript-ecosystem-part-7/) by Marvin Hagemeister\n\n...the conclusion is the same: barrel files slow down tests.\n\n> The problem is that Jest has no idea where the component we’re importing is located. The barrel file has intentionally obfuscated that fact. So when Jest hits a barrel file, it must load every export referenced inside it. This behavior quickly gets out of hand for large libraries like `@mui/material`. We’re looking for a single button and end up loading hundreds of additional files.\n\nLet's run the same test suite on two modules:\n\n- **Importing from barrel file:**\n\n```jsx\nimport { Button } from \"@mui/material\";\n\nexport function App() {\n  return <Button>Text</Button>;\n}\n```\n\n```\n> node scripts/test.js\n\n PASS  src/App.test.js\n  ✓ renders button (25 ms)\n\nTest Suites: 1 passed, 1 total\nTests:       1 passed, 1 total\nTime:        1.717 s, estimated 2 s\n```\n\n- **Importing directly from the module:**\n\n```diff\n-import { Button } from \"@mui/material\";\n+import Button from \"@mui/material/Button\";\n\nexport function App() {\n  return <Button>Text</Button>;\n}\n```\n\n```\n> node scripts/test.js\n\n PASS  src/App.test.js\n  ✓ renders button (29 ms)\n\nTest Suites: 1 passed, 1 total\nTests:       1 passed, 1 total\nTime:        1.097 s\n```\n\n<Alert type=\"success\">\n  The test duration <u>decreased from ~1.7 to ~1.1 seconds</u> when not importing from a barrel file.\n</Alert>\n\nNotice the test suite itself took 25-29ms. The 600ms overhead comes from building the module graph. The cost of loading modules can change depending on the machine and the tooling.\n\nIn my lab setup, 10 independent tests running in 4 child processes would result in a $$\\frac{0.6 \\times 10}{4} = 1.5$$ seconds overhead.\n\n## The lint-time cost\n\nBarrel files affect the linting performance. Let’s say you use the `import/no-cycle` rule from `eslint-plugin-import`, which ensures there is no resolvable path back to a module via its dependencies by building a dependency graph. When it comes across a barrel file, the linting time will take longer because it has to resolve all the exports from the barrel file.\n\n<Alert type=\"info\">\n  Unlike testing, linting is done on a file basis, so the dependency graph is built for each file separately.\n</Alert>\n\n## Developer experience\n\n1. Most (if not all) IDEs have autocomplete and IntelliSense - you can type the function name, and it will get the import right automatically.\n\n2. Having barrel files makes code navigation harder - <kbd>CMD + click</kbd> navigates to the barrel file instead of the actual definition of the module.\n\n## Conclusion\n\nAs software engineers, we are implementing new features daily, and each one has to be covered by _tests_. To do so, we use _linters_ to help us write better code faster. Then, we _build_ our app for a testing environment before releasing it to production (_another build_), and so on...\n\nBuilds, tests, and tooling will only get slower as the application grows. Avoiding barrel files can improve performance without compromising the architecture or the developer experience.\n","excerpt":"Barrel files consolidate the exports of multiple modules into a single file. We use them to import a module using a single import statement without…","tableOfContents":{"items":[{"url":"#the-bundle-size-cost","title":"The bundle size cost"},{"url":"#the-build-time-cost","title":"The build-time cost"},{"url":"#the-test-time-cost","title":"The test-time cost"},{"url":"#the-lint-time-cost","title":"The lint-time cost"},{"url":"#developer-experience","title":"Developer experience"},{"url":"#conclusion","title":"Conclusion"}]},"fields":{"slug":"/blog/pitfalls-of-barrel-files-in-javascript-modules/","timeToRead":{"minutes":5.26,"words":1052}},"frontmatter":{"title":"Why you should avoid Barrel Files in JavaScript Modules?","authors":["Bartosz Łaniewski"],"keywords":["JavaScript","Architecture"],"language":"en","description":null,"dateCreated":"March 27, 2024","dateCreatedMeta":"2024-03-28 00:00:00 +0100","dateUpdated":"April 05, 2024","dateUpdatedMeta":"2024-04-05 14:30:00 +0100","datePublished":"April 05, 2024","datePublishedMeta":"2024-04-05 14:00:00 +0100"},"internal":{"contentFilePath":"/home/runner/work/bartozzz.github.io/bartozzz.github.io/content/blog/pitfalls-of-barrel-files-in-javascript-modules/index.md"}},{"id":"c74a6bf9-c7da-5c5e-ba71-ad3b9f16694f","body":"\nAdding structured data can help search engines understand more about your web pages and show better, richer results. Rich snippets enhance the appearance of search results by providing additional information beyond the standard meta description. In this article, we’ll dive into structuring content for rich snippets and explore best practices for optimizing your website’s presence in search engine results.\n\n## What are rich snippets?\n\nRich snippets are the extra pieces of information that appear in search results, providing users with a snapshot of what to expect on a webpage. These snippets can include various elements such as reviews, ratings, pricing, event details, and more. By presenting this additional information, rich snippets not only make search results more informative but also make your content stand out, potentially attracting more clicks.\n\n## How to structure data for rich snippets?\n\nTo enable search engines to understand and display rich snippets, you need to utilize specific markup languages. The two primary markup languages for this purpose are **Microdata** and <abbr title=\"JavaScript Object Notation for Linked Data\">**JSON-LD**</abbr>.\n\n### Step 1: Identify Content Types\n\nStart by identifying the specific content types that could benefit from rich snippets. Common types include [reviews](https://schema.org/AggregateRating), [recipes](https://schema.org/Recipe), [events](https://schema.org/Event), [FAQs](https://schema.org/FAQPage), and more.\n\n### Step 2: Decide which format to use\n\nGoogle recommends using [JSON-LD](https://json-ld.org/) due to its simplicity and ease of implementation. I prefer to use Microdata, because I can put it directly into the reusable components (and layouts) I use to build a webpage. Remember that you can mix both syntaxes (Microdata and JSON-LD):\n\n> - I can have on the same page both syntaxes (microdata and json-ld); for instance I might use microdata to render WebPage and use json-ld for Organization;\n> - I can also merge attributes related to the same entity when all the data is available in json-ld but…\n> - I cannot combine information related to the same entity by item ID when this information is written in microdata and json-ld.\n>\n> – [„Mixing JSON-LD and Microdata: All You Need to Know” by Andrea Volpini](https://wordlift.io/blog/en/mixing-json-ld-and-microdata/)\n\n### Step 3: Use Structured Data Markup\n\nOnce you’ve identified content types and chosen the preferred format, you need to implement structured data. This involves embedding code within your HTML that provides explicit information about the content on the page.\n\n<Newsletter />\n\nWhen implementing structured data, you should follow [Schema.org Guidelines](https://schema.org/). Schema.org is a collaborative project between major search engines, including Google, Bing, and Yahoo. It provides a standardized vocabulary for structured data markup.\n\n#### JSON-LD example\n\nIf you followed my last article [about creating an SEO component for Gatsby](/blog/ultimate-gatsby-seo-guide/how-to-create-an-seo-component/), you can paste JSON-LD snippets directly there. Here's an example of an article with JSON-LD structured data:\n\n```tsx\nexport function Head() {\n  return (\n    <SEO>\n      <script type=\"application/ld+json\">\n        {JSON.stringify({\n          \"@context\": \"https://schema.org\",\n          \"@type\": \"BlogPosting\",\n          \"headline\": \"Title of the article\",\n          \"datePublished\": \"2023-12-20T12:00:00+01:00\",\n          \"dateModified\": \"2023-12-26T14:20:00+01:00\",\n          \"image\": [\"https://example.com/thumbnail.png\"],\n          \"author\": [\n            {\n              \"@type\": \"Person\",\n              \"name\": \"Jan Kowalski\",\n              \"url\": \"https://example.com/profile/j.kowalski\"\n            }\n          ]\n        })}\n      </script>\n    </SEO>\n  );\n}\n```\n\n<Alert type=\"info\">\n  There are some free tools you can use to generate structured data markup for your website, for example, [Merkle’s Schema Markup Generator](https://technicalseo.com/tools/schema-markup-generator/) which generates JSON-LD for most common types.\n</Alert>\n\n#### Microdata example\n\nHere’s an example of an article using Microdata:\n\n```tsx\nfunction BlogPostTemplate({ post }) {\n  return (\n    <article\n      itemScope\n      itemType=\"http://schema.org/Article\"\n      lang={post.language}\n    >\n      <meta itemProp=\"image\" content={post.thumbnailUrl} />\n      <meta itemProp=\"dateModified\" content={post.dateUpdatedISO} />\n\n      <header>\n        <h1 itemProp=\"headline\">{post.title}</h1>\n\n        <span\n          itemScope\n          itemProp=\"author\"\n          itemType=\"https://schema.org/Person\"\n        >\n          By <span itemProp=\"name\">{post.author}</span>\n        </span>\n\n        <time itemProp=\"datePublished\" dateTime={post.datePublishedISO}>\n          Published on {post.datePublished}\n        </time>\n      </header>\n\n      <div itemProp=\"articleBody\">\n        {post.body}\n      </div>\n    </article>\n  );\n}\n```\n\n- `itemScope` defines the scope of associated metadata ([docs](https://developer.mozilla.org/en-US/docs/Web/HTML/Global_attributes/itemscope));\n- `itemType` specifies the vocabulary that will be used to define item properties ([docs](https://developer.mozilla.org/en-US/docs/Web/HTML/Global_attributes/itemtype));\n- `itemProp` is used to add properties to an item ([docs](https://developer.mozilla.org/en-US/docs/Web/HTML/Global_attributes/itemprop));\n\n<Alert type=\"info\">\n  If you want to create markup by hand, I recommend checking out the [Google Developers Structured Data Search Gallery](https://developers.google.com/search/docs/appearance/structured-data/search-gallery) for examples.\n</Alert>\n\n## How to test Structured Data?\n\n- [Rich Result Test](https://search.google.com/test/rich-results) is the official Google tool for testing your structured data to see which Google-rich results can be generated by the structured data on your page.\n\n- [Schema Markup Validator](https://validator.schema.org/) validates all [Schema.org](https://schema.org/)-based structured data that is embedded in web pages, without Google feature-specific warnings.\n\n- [Structured data linter](http://linter.structured-data.org/) previews an example of what a search engine might display. Remember, it is at the discretion of each search engine provider to decide whether your page will be displayed as an enhanced search result or not in their search results pages.\n\n## Conclusion\n\nStructuring content for rich snippets is a powerful SEO strategy that can significantly enhance your online visibility. By implementing structured data markup using best practices, you can increase the chances of your content being featured in search results, attracting more clicks and driving organic traffic to your website.\n","excerpt":"Adding structured data can help search engines understand more about your web pages and show better, richer results. Rich snippets enhance the appearance…","tableOfContents":{"items":[{"url":"#what-are-rich-snippets","title":"What are rich snippets?"},{"url":"#how-to-structure-data-for-rich-snippets","title":"How to structure data for rich snippets?","items":[{"url":"#step-1-identify-content-types","title":"Step 1: Identify Content Types"},{"url":"#step-2-decide-which-format-to-use","title":"Step 2: Decide which format to use"},{"url":"#step-3-use-structured-data-markup","title":"Step 3: Use Structured Data Markup"}]},{"url":"#how-to-test-structured-data","title":"How to test Structured Data?"},{"url":"#conclusion","title":"Conclusion"}]},"fields":{"slug":"/blog/ultimate-gatsby-seo-guide/how-to-structure-data-for-rich-snippets/","timeToRead":{"minutes":3.95,"words":790}},"frontmatter":{"title":"Ultimate Gatsby SEO Guide: How to structure data for rich snippets?","authors":["Bartosz Łaniewski"],"keywords":["Gatsby","SEO"],"language":"en","description":null,"dateCreated":"December 26, 2023","dateCreatedMeta":"2023-12-26 10:00:00 +0100","dateUpdated":"January 07, 2024","dateUpdatedMeta":"2024-01-07 20:45:00 +0100","datePublished":"January 07, 2024","datePublishedMeta":"2024-01-07 20:45:00 +0100"},"internal":{"contentFilePath":"/home/runner/work/bartozzz.github.io/bartozzz.github.io/content/blog/ultimate-gatsby-seo-guide/how-to-structure-data-for-rich-snippets.md"}},{"id":"e3c6f8f5-1fe5-5588-8f80-d262181f4e77","body":"\nAs a software engineer, I love to automate things. I also love to write blog posts. So I decided to automate the process of generating thumbnails for my Gatsby blog to improve my brand consistency and recognition across social media platforms. In this article, I will show you how to do it.\n\n## Why are thumbnails important?\n\n1. **First Impression Matter**\n\nBlog post thumbnails act as the visual ambassadors of your content, offering a sneak peek into the article. A compelling thumbnail serves as the initial point of contact between your content and potential readers, making it a low-hanging fruit determining whether users will click through or scroll past.\n\n2. **Social Media Optimization**\n\nBlog post thumbnails are important in optimizing content for platforms like Facebook, Twitter, and Instagram. Social media users often scroll through feeds rapidly, and a striking thumbnail can make your content stand out. It acts as a visual anchor, inviting users to pause and delve deeper into your blog.\n\n3. **Increased Click-Through Rates**\n\nA well-crafted thumbnail can significantly boost click-through rates. When users are presented with a visually appealing and relevant image, they are more likely to be enticed into exploring the full article. This not only enhances the visibility of your content but also contributes to the overall success of your blog by increasing engagement metrics.\n\n## Step 1: Prepare HTML image template\n\nOur thumbnails will be created based on a parametrized HTML template. We will then use a library to convert the HTML to an image. The template should contribute to brand consistency and recognition. Here’s a basic template you can use as a starting point:\n\n```html\n<!DOCTYPE html>\n<html>\n  <head>\n    <style>\n      :root {\n        --imgWidth: {{imgWidth}};\n        --imgHeight: {{imgHeight}};\n      }\n\n      html, body {\n        margin: 0;\n      }\n\n      body {\n        width: var(--imgWidth);\n        height: var(--imgHeight);\n      }\n    </style>\n  </head>\n  <body>\n    <p class=\"title\">{{title}}</p>\n    <p class=\"domain\">{{link}}</p>\n  </body>\n</html>\n```\n\n<Alert type=\"info\">\n  `{{title}}`, `{{link}}`, `{{imgWidth}}`, and `{{imgHeight}}` are variables that will be replaced during the image generation phase.\n</Alert>\n\n## Step 2: Create a function to generate thumbnails\n\nThere are plenty of libraries that can be used to convert HTML to an image. I decided to use [`node-html-to-image`](https://www.npmjs.com/package/node-html-to-image) as it provides a simple, easy-to-use API. It also allows us to generate multiple images in one call, which benefits performance.\n\nTo get started, install the library using the following command:\n\n```bash\n$ npm install node-html-to-image\n```\n\nNext, let’s create a function that will accept a list of blog posts and generate thumbnails for each of them:\n\n```js\nimport nodeHtmlToImage from \"node-html-to-image\";\n\nconst html = `<YOUR_HTML_TEMPLATE>`;\n\nfunction mapSlugToImageName(slug) {\n  return slug\n    .replace(/\\/$/, \"\") // Remove trailing slash\n    .replace(\"/\", \"-\"); // Replace slashes with dashes\n}\n\nfunction buildOutputPath(slug) {\n  return `./static/thumbnails/${mapSlugToImageName(slug)}.png`;\n}\n\nfunction buildLinkPath(slug) {\n  return `https://example.com${slug}`;\n}\n\nexport async function createBlogPostThumbnails(posts) {\n  return nodeHtmlToImage({\n    html,\n    content: posts.map((post) => ({\n      output: buildOutputPath(post.slug),\n      // Parameters to be passed to the template:\n      link: buildLinkPath(post.slug),\n      title: post.title,\n      imgWidth: 1600,\n      imgHeight: 900,\n    })),\n  });\n}\n```\n\n<Newsletter />\n\n## Step 3: Create thumbnails when building pages\n\nThe function will be called in the `gatsby-node.js` file, in the `createPages` hook. First, we need to fetch a list of all blog posts. Then, we can call the `createBlogPostThumbnails` function with the data. The function will return a promise that will resolve once all thumbnails are generated.\n\n```js\nexport const createPages = async ({ graphql }) => {\n  const allPostsResult = await graphql(`\n    query AllPostsQuery {\n      allMdx {\n        nodes {\n          frontmatter {\n            title\n          }\n          fields {\n            slug\n          }\n        }\n      }\n    }\n  `);\n\n  await createBlogPostThumbnails(\n    allPostsResult.allMdx.nodes.map((post) => ({\n      title: post.frontmatter.title,\n      slug: post.fields.slug,\n    })),\n  );\n};\n```\n\n## Step 4: Use images in your SEO component\n\nIf you followed my last article [about creating an SEO component for Gatsby](/blog/ultimate-gatsby-seo-guide/how-to-create-an-seo-component/), you can now use the generated thumbnails for social sharing cards. We simply have to generate a link to the image and pass it to the `image` property of the `SEO` component. Here’s a rough idea of how it could look like:\n\n```tsx\nexport function Head({ data, location }: HeadProps<DataType, PageContextType>) {\n  const slug = location.pathname;\n  const siteUrl = data.site.siteMetadata.siteUrl;\n  const thumbnailUrl = `${siteUrl}/thumbnails/${mapSlugToImageName(slug)}.png`;\n\n  return <SEO {/* other props */} image={thumbnailUrl} />;\n}\n\nexport const query = graphql`\n  {\n    site {\n      siteMetadata {\n        siteUrl\n      }\n    }\n  }\n`;\n```\n\n## Conclusion\n\nIn a world where information competes for attention, blog post thumbnails are a powerful tool in every content creator’s arsenal. By automating thumbnail generation, you can save time and effort and focus on what’s important – creating great content.\n","excerpt":"As a software engineer, I love to automate things. I also love to write blog posts. So I decided to automate the process of generating thumbnails for my…","tableOfContents":{"items":[{"url":"#why-are-thumbnails-important","title":"Why are thumbnails important?"},{"url":"#step-1-prepare-html-image-template","title":"Step 1: Prepare HTML image template"},{"url":"#step-2-create-a-function-to-generate-thumbnails","title":"Step 2: Create a function to generate thumbnails"},{"url":"#step-3-create-thumbnails-when-building-pages","title":"Step 3: Create thumbnails when building pages"},{"url":"#step-4-use-images-in-your-seo-component","title":"Step 4: Use images in your SEO component"},{"url":"#conclusion","title":"Conclusion"}]},"fields":{"slug":"/blog/ultimate-gatsby-seo-guide/how-to-automatically-generate-thumbnails/","timeToRead":{"minutes":3.72,"words":744}},"frontmatter":{"title":"Ultimate Gatsby SEO Guide: How to generate thumbnails?","authors":["Bartosz Łaniewski"],"keywords":["Gatsby","SEO"],"language":"en","description":null,"dateCreated":"December 16, 2023","dateCreatedMeta":"2023-12-16 13:10:00 +0100","dateUpdated":"December 25, 2023","dateUpdatedMeta":"2023-12-26 00:00:00 +0100","datePublished":"December 16, 2023","datePublishedMeta":"2023-12-16 16:45:00 +0100"},"internal":{"contentFilePath":"/home/runner/work/bartozzz.github.io/bartozzz.github.io/content/blog/ultimate-gatsby-seo-guide/how-to-automatically-generate-thumbnails.md"}},{"id":"bdc34da5-64ce-5d46-a072-95239ffc5c0a","body":"\nOne way to enhance your Gatsby site’s SEO capabilities is by creating a custom SEO component for easy metadata tag management. In this blog post, we’ll explore the Head API and a step-by-step guide on creating a Gatsby SEO component.\n\n## What is the Gatsby Head API?\n\n[Gatsby Head API](https://www.gatsbyjs.com/docs/reference/built-in-components/gatsby-head/) simplifies the process of managing the [document head](https://developer.mozilla.org/en-US/docs/Web/HTML/Element/head), where metadata such as title tags, meta descriptions, and other elements crucial for SEO are defined.\n\nTo use the Head API, you simply have to export a named function called `Head` from your pages (and templates used in `createPage`), as follows:\n\n```tsx\nexport function Head(props: HeadProps<DataType, PageContextType>) {\n  return (\n    <>\n      <title>…</title>\n      <meta name=\"keywords\" content=\"…\" />\n      <meta name=\"description\" content=\"…\" />\n    </>\n  );\n}\n```\n\nYou can read more about the Gatsby Head API in the official documentation [here](https://www.gatsbyjs.com/docs/reference/built-in-components/gatsby-head/).\n\n## Step 1: Create a basic SEO component\n\nLet’s start by creating a new `components/SEO.tsx` component that will set basic metadata information in the document head:\n\n```tsx\ninterface SEOProps {\n  title: string;\n  description: string;\n}\n\nexport function SEO({ title, description }: React.PropsWithChildren<SEOProps>) {\n  return (\n    <>\n      <title>{title}</title>\n      <meta name=\"description\" content={description} />\n\n      {children}\n    </>\n  );\n};\n```\n\nOur basic component accepts 3 properties:\n- `title`: the title of the page;\n- `description`: the description of the page;\n- `children`: any additional elements that should be included in the document head;\n\nWe can now use the component inside pages and templates, as follows:\n\n```tsx\nexport function Head() {\n  return (\n    <SEO title=\"Page title\" description=\"Page description\">\n      <html lang=\"en\" />\n    </SEO>\n  );\n}\n```\n\n<Newsletter />\n\n## Step 2: Add canonical links\n\nA canonical tag defines the main version for duplicate and similar pages. It tells search engines which version of a page they should index and rank (for example, to use https://example.com instead of https://www.example.com). To add canonical links, you can use the official Gatsby plugin called [`gatsby-plugin-canonical-urls`](https://www.gatsbyjs.com/plugins/gatsby-plugin-canonical-urls/). It works well for most cases.\n\nFor a more customizable approach, we can leverage the Head API and the `location` property to create custom canonical links. Let’s start by extending our SEO component with a `url` property:\n\n```tsx {4,10,18}\nimport { useStaticQuery, graphql } from \"gatsby\";\n\ninterface SEOProps {\n  url: string;\n  title: string;\n  description: string;\n}\n\nexport function SEO({\n  url,\n  title,\n  description,\n  children,\n}: React.PropsWithChildren<SEOProps>) {\n  return (\n    <>\n      <title>{title}</title>\n      <link rel=\"canonical\" href={url} />\n      <meta name=\"description\" content={description} />\n\n      {children}\n    </>\n  );\n}\n```\n\nThen, we can populate the `url` property in our pages and templates, as follows:\n\n```tsx\ninterface DataType {\n  site: {\n    siteMetadata: {\n      siteUrl: string;\n    };\n  };\n};\n\nexport function Head({ data, location }: HeadProps<DataType>) {\n  const siteUrl = data.site.siteMetadata.siteUrl;\n  const slug = location.pathname;\n\n  return (\n    <SEO\n      url={`${siteUrl}${slug}`}\n      title=\"Page title\"\n      description=\"Page description\"\n    />\n  );\n}\n\nexport const query = graphql`\n  {\n    site {\n      siteMetadata {\n        siteUrl\n      }\n    }\n  }\n`;\n```\n\n## Step 3: Add social sharing cards\n\nOpen Graph (OG) tags instruct social networks like Facebook, Pinterest, LinkedIn, and other platforms what information to display whenever a URL to your page is shared. The four required Open Graph tags for every page are:\n- `og:title`,\n- `og:type`,\n- `og:image`,\n- `og:url`.\n\nTwitter provides its variants of those tags. Basic Twitter cards include:\n- `twitter:card`,\n- `twitter:site`,\n- `twitter:title`,\n- `twitter:description`,\n- `twitter:image`.\n\nAccording to [Twitter Documentation](https://developer.twitter.com/en/docs/twitter-for-websites/cards/guides/getting-started), if some of these tags are missing, Twitter will pull data from relevant Open Graph tags.\n\n<Alert type=\"warning\">\n  Make sure the URL specified in `og:url` matches the URL of the canonical page unless you have a specific intent.\n</Alert>\n\n```tsx {7,14,17-25,27,35-42}\nimport { useStaticQuery, graphql } from \"gatsby\";\n\ninterface SEOProps {\n  url: string;\n  title: string;\n  description: string;\n  image?: string;\n}\n\nexport function SEO({\n  url,\n  title,\n  description,\n  image,\n  children,\n}: React.PropsWithChildren<SEOProps>) {\n  const { site } = useStaticQuery(graphql`\n    query {\n      site {\n        siteMetadata {\n          siteUrl\n        }\n      }\n    }\n  `);\n\n  const metaImage = image || `${site.siteMetadata.siteUrl}/thumbnail.png`;\n\n  return (\n    <>\n      <title>{title}</title>\n      <link rel=\"canonical\" href={url} />\n      <meta name=\"description\" content={description} />\n\n      <meta name=\"og:url\" content={url} />\n      <meta name=\"og:type\" content=\"website\" />\n      <meta name=\"og:image\" content={metaImage} />\n      <meta name=\"og:title\" content={title} />\n      <meta name=\"og:description\" content={description} />\n      <meta name=\"twitter:card\" content=\"summary_large_image\" />\n      <meta name=\"twitter:title\" content={title} />\n      <meta name=\"twitter:creator\" content=\"@yourTwitterHandle\" />\n\n      {children}\n    </>\n  );\n}\n```\n\nUnfortunately, you cannot test Open Graph and Twitter cards locally, you need to deploy your changes so they are publicly accessible. Once deployed, you can post a link to your website in the [Facebook Debugger](https://developers.facebook.com/tools/debug) and Tweet Composer (in the Twitter client itself) to check that your cards render as expected.\n\n## Conclusion\n\nCreating a custom SEO component with Gatsby and the Head API is a straightforward process that significantly enhances your website’s search engine visibility. Managing metadata efficiently will empower you to create well-optimized pages that stand out in search engine rankings, ultimately driving more traffic to your website.\n","excerpt":"One way to enhance your Gatsby site’s SEO capabilities is by creating a custom SEO component for easy metadata tag management. In this blog post, we’ll…","tableOfContents":{"items":[{"url":"#what-is-the-gatsby-head-api","title":"What is the Gatsby Head API?"},{"url":"#step-1-create-a-basic-seo-component","title":"Step 1: Create a basic SEO component"},{"url":"#step-2-add-canonical-links","title":"Step 2: Add canonical links"},{"url":"#step-3-add-social-sharing-cards","title":"Step 3: Add social sharing cards"},{"url":"#conclusion","title":"Conclusion"}]},"fields":{"slug":"/blog/ultimate-gatsby-seo-guide/how-to-create-an-seo-component/","timeToRead":{"minutes":3.915,"words":783}},"frontmatter":{"title":"Ultimate Gatsby SEO Guide: How to create an SEO component?","authors":["Bartosz Łaniewski"],"keywords":["Gatsby","SEO"],"language":"en","description":null,"dateCreated":"December 15, 2023","dateCreatedMeta":"2023-12-15 18:10:00 +0100","dateUpdated":"December 25, 2023","dateUpdatedMeta":"2023-12-26 00:00:00 +0100","datePublished":"December 15, 2023","datePublishedMeta":"2023-12-15 18:10:00 +0100"},"internal":{"contentFilePath":"/home/runner/work/bartozzz.github.io/bartozzz.github.io/content/blog/ultimate-gatsby-seo-guide/how-to-create-an-seo-component.md"}},{"id":"35de612c-7f7a-55a1-a367-17364698e251","body":"\nCreating a sitemap is an essential step towards enhancing the visibility and SEO performance of your Gatsby website. A sitemap assists search engines in efficiently crawling and indexing your content. In this guide, I’ll walk you through the process of creating a sitemap for your Gatsby project, boosting its search engine optimization.\n\n## The Importance of a Sitemap\n\nA sitemap serves as a guide for search engines, helping them discover and rank your content more effectively. It also ensures that any updates or new pages are recognized. This is crucial for Search Engine Optimization (_SEO_) and ensuring that your website appears in Search Engine Results Pages (_SERPs_).\n\n## Step 1: Install the Gatsby Plugin\n\nGatsby simplifies the process of creating a sitemap by providing an official, dedicated plugin – [`gatsby-plugin-sitemap`](https://www.gatsbyjs.com/plugins/gatsby-plugin-sitemap/). To get started, open your Gatsby project and install the plugin using the following command:\n\n```bash\n$ npm install gatsby-plugin-sitemap\n```\n\nNext, integrate the plugin into your `gatsby-config.js` file:\n\n```javascript\nmodule.exports = {\n  siteMetadata: {\n    siteUrl: \"https://www.example.com\",\n  },\n  plugins: [\n    {\n      resolve: \"gatsby-plugin-sitemap\",\n    },\n  ],\n}\n```\n\nThis step automatically generates a `sitemap-index.xml` file in the root of your Gatsby project and, for every 45000 URLs a new `sitemap-n.xml` file containing all the basic information for search engines:\n\n```xml\n<!-- sitemap-index.xml -->\n<sitemapindex xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n  <sitemap>\n    <loc>https://example.com/sitemap-0.xml</loc>\n  </sitemap>\n</sitemapindex>\n```\n\n```xml\n<!-- sitemap-0.xml -->\n<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\" xmlns:news=\"http://www.google.com/schemas/sitemap-news/0.9\" xmlns:xhtml=\"http://www.w3.org/1999/xhtml\" xmlns:image=\"http://www.google.com/schemas/sitemap-image/1.1\" xmlns:video=\"http://www.google.com/schemas/sitemap-video/1.1\">\n  <url>\n    <loc>https://example.com/blog/some-post-slug/</loc>\n    <changefreq>daily</changefreq>\n    <priority>0.7</priority>\n  </url>\n  <url>\n    <loc>https://example.com/blog/</loc>\n    <changefreq>daily</changefreq>\n    <priority>0.7</priority>\n  </url>\n  <url>\n    <loc>https://example.com/</loc>\n    <changefreq>daily</changefreq>\n    <priority>0.7</priority>\n  </url>\n</urlset>\n```\n\n## Step 2: Customize Your Sitemap\n\nWhile the default configuration works well, you may want to customize your sitemap to provide more information. Gatsby allows you to tailor the sitemap by [providing options](https://www.gatsbyjs.com/plugins/gatsby-plugin-sitemap/) in the `gatsby-config.js` file, as follows:\n\n```javascript\nmodule.exports = {\n  plugins: [\n    {\n      resolve: \"gatsby-plugin-sitemap\",\n      options: {\n        query: `\n          {\n            site {\n              siteMetadata {\n                siteUrl\n              }\n            }\n            allSitePage {\n              nodes {\n                path\n              }\n            }\n            allMdx {\n              nodes {\n                fields {\n                  slug\n                }\n                frontmatter {\n                  dateUpdated\n                }\n              }\n            }\n          }\n        `,\n        resolvePages: ({\n          allSitePage: { nodes: allSitePages },\n          allMdx: { nodes: allMdxNodes },\n        }) => {\n          const blogPostsPages = allMdxNodes.reduce(\n            (acc, node) => ({\n              ...acc,\n              [node.fields.slug]: node.frontmatter,\n            }),\n            {},\n          );\n\n          return allSitePages.map((page) => ({\n            ...page,\n            ...blogPostsPages[page.path],\n          }));\n        },\n        serialize: ({ path, dateUpdated }) => {\n          if (dateUpdated) {\n            return {\n              url: path,\n              lastmod: dateUpdated,\n              priority: 0.7,\n              changefreq: \"daily\",\n            };\n          } else {\n            return {\n              url: path,\n              priority: 0.5,\n              changefreq: \"daily\",\n            };\n          }\n        },\n      },\n    },\n  ],\n}\n```\n\nWith the configuration above, the new sitemap should contain the new field `<lastmod>` when the last update date is available for a given page:\n\n```xml\n<!-- sitemap-0.xml -->\n<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\" xmlns:news=\"http://www.google.com/schemas/sitemap-news/0.9\" xmlns:xhtml=\"http://www.w3.org/1999/xhtml\" xmlns:image=\"http://www.google.com/schemas/sitemap-image/1.1\" xmlns:video=\"http://www.google.com/schemas/sitemap-video/1.1\">\n  <url>\n    <loc>https://example.com/blog/some-post-slug/</loc>\n    <lastmod>2023-01-01T00:00:00.000Z</lastmod>\n    <changefreq>daily</changefreq>\n    <priority>0.7</priority>\n  </url>\n  <url>\n    <loc>https://example.com/blog/</loc>\n    <changefreq>daily</changefreq>\n    <priority>0.5</priority>\n  </url>\n  <url>\n    <loc>https://example.com/</loc>\n    <changefreq>daily</changefreq>\n    <priority>0.5</priority>\n  </url>\n</urlset>\n```\n\n<Alert type=\"info\">\n  **Crawlers interpret the sitemap differently.** For instance, [Google ignores `<priority>` and `<changefreq>` values](https://developers.google.com/search/docs/crawling-indexing/sitemaps/build-sitemap?hl=en&visit_id=638379916569097492-3578546875&rd=1#additional-notes-about-xml-sitemaps), but recommends adding a `<lastmod>` value to indicate the last update date for a given page.\n</Alert>\n\n## Step 3: Update your robots.txt file\n\nThe `robots.txt` file is a text file placed in a website’s root directory to instruct web crawlers about which parts of the site should not be crawled or indexed. The `Sitemap` directive in the `robots.txt` file is used to indicate the location of the XML sitemap.\n\nTo generate a `robots.txt` file, you can use the [`gatsby-plugin-robots-txt`](https://www.gatsbyjs.com/plugins/gatsby-plugin-robots-txt/) plugin. For our use case, we won’t overengineer the configuration. Let’s manually create a `robots.txt` file in the `static` folder and simply add a reference to the sitemap file to allow all crawlers to index our website:\n\n```txt\nSitemap: https://example.com/sitemap-index.xml\nUser-agent: *\nDisallow:\n```\n\n<Newsletter />\n\n## Step 4: Test and Deploy\n\nBefore deploying your Gatsby website with the new sitemap, it’s crucial to test it locally. The sitemap is only generated for production mode. To test your sitemap, you should run the following command:\n\n```bash\n$ gatsby build && gatsby serve.\n```\n\n…and head to `localhost:9000/sitemap-index.xml` to see the generated sitemap. Once you’ve confirmed that everything is working as expected, deploy your Gatsby website to your hosting provider.\n\n## Step 5: Submit to search engines\n\nThe next step is to submit it to major search engines. Google Search Console, Bing Webmaster Tools, and other search engine platforms provide tools for submitting and monitoring your sitemap.\n\n### How to submit a sitemap to Google Search Console\n\n1. Sign in to [Google Search Console](https://search.google.com/search-console) and select your website;\n2. In the navigation menu, in the **Indexing** section, click on **Sitemaps**;\n3. Enter a full sitemap URL in the **Add a new sitemap** field and click **Submit**.\n\n### How to submit a sitemap to Bing Webmaster Tools\n\n1. Sign in to [Bing Webmaster Tools](https://www.bing.com/webmasters/about) and select your website.\n2. In the navigation menu, click on **Sitemaps**, then click on **Submit sitemap**;\n4. Enter a full sitemap URL in the **Submit sitemap** field and click **Submit**.\n\n## Conclusion\n\nCreating a sitemap for your Gatsby website is a strategic move towards improving SEO and making your content more accessible to search engines.\n\nThe `gatsby-plugin-sitemap` simplifies this process, allowing you to focus on creating compelling content while ensuring that search engines can easily discover and index your pages.\n\nBy following these steps and customizing your sitemap, you can increase visibility, and ultimately optimize your website’s performance.\n","excerpt":"Creating a sitemap is an essential step towards enhancing the visibility and SEO performance of your Gatsby website. A sitemap assists search engines in…","tableOfContents":{"items":[{"url":"#the-importance-of-a-sitemap","title":"The Importance of a Sitemap"},{"url":"#step-1-install-the-gatsby-plugin","title":"Step 1: Install the Gatsby Plugin"},{"url":"#step-2-customize-your-sitemap","title":"Step 2: Customize Your Sitemap"},{"url":"#step-3-update-your-robotstxt-file","title":"Step 3: Update your robots.txt file"},{"url":"#step-4-test-and-deploy","title":"Step 4: Test and Deploy"},{"url":"#step-5-submit-to-search-engines","title":"Step 5: Submit to search engines","items":[{"url":"#how-to-submit-a-sitemap-to-google-search-console","title":"How to submit a sitemap to Google Search Console"},{"url":"#how-to-submit-a-sitemap-to-bing-webmaster-tools","title":"How to submit a sitemap to Bing Webmaster Tools"}]},{"url":"#conclusion","title":"Conclusion"}]},"fields":{"slug":"/blog/ultimate-gatsby-seo-guide/how-to-create-a-sitemap/","timeToRead":{"minutes":4.37,"words":874}},"frontmatter":{"title":"Ultimate Gatsby SEO Guide: How to create a sitemap?","authors":["Bartosz Łaniewski"],"keywords":["Gatsby","SEO"],"language":"en","description":null,"dateCreated":"December 11, 2023","dateCreatedMeta":"2023-12-12 00:00:00 +0100","dateUpdated":"December 25, 2023","dateUpdatedMeta":"2023-12-26 00:00:00 +0100","datePublished":"December 11, 2023","datePublishedMeta":"2023-12-12 00:00:00 +0100"},"internal":{"contentFilePath":"/home/runner/work/bartozzz.github.io/bartozzz.github.io/content/blog/ultimate-gatsby-seo-guide/how-to-create-a-sitemap.md"}},{"id":"f49d0a2d-3925-5ae5-8320-57422f8b715f","body":"\nWhen implementing applications, we often need to communicate with external services via APIs. In such cases, it’s crucial to ensure that the data received from these APIs is valid and conforms to the expected format. It’s essential for maintaining the integrity and functionality of various systems.\n\n## What is Zod\n\n[Zod](https://github.com/colinhacks/zod) is a TypeScript-first schema declaration and validation library. It provides an elegant and expressive syntax for defining data schemas and validating data against those schemas in the runtime. Here’s a simple example using TypeScript:\n\n```ts\nimport { z } from \"zod\";\n\nconst userSchema = z.object({\n  id: z.string().uuid(),\n  email: z.string().email(),\n  login: z.string(),\n  createdAt: z.string().datetime(),\n  deletedAt: z.string().datetime().nullable(),\n});\n\nconst userData = {\n  id: \"3f740a80-0af0-4976-9bad-db83b15c7bf7\",\n  email: \"jan.kowalski@example.com\",\n  login: \"jan.kowalski\",\n  createdAt: \"2020-01-01T00:00:00Z\",\n  deletedAt: null,\n};\n\ntry {\n  const validatedUser = userSchema.parse(userData);\n\n  console.log(validatedUser);\n} catch (error) {\n  console.error(error.errors);\n}\n```\n\nIn this example, `userSchema` defines a schema for user data, specifying the expected types and constraints for each field. The `parse` method is then used to validate the `userData` object against the schema. If validation fails, an error is thrown with details about the validation errors.\n\n## Why use Zod\n\n- **Type Safety:** Zod integrates seamlessly with TypeScript, providing strong type checking at compile-time. This helps to catch potential issues early in the development process.\n\n- **Error Reporting:** When validation fails in the run-time, Zod provides detailed error messages, including information about the specific fields that didn’t pass validation. This aids in diagnosing and fixing issues efficiently.\n\n- **Readability and Expressiveness:** Zod’s syntax is clean and expressive, making it easy to define and understand complex data structures. This enhances code readability and maintainability.\n\n- **Flexibility:** Zod allows you to create sophisticated validation rules, including custom validation functions, conditional validation, and more. This flexibility is valuable when dealing with diverse and evolving data structures.\n\n<Newsletter />\n\n## How to use Zod\n\nIn a real application, I’d encourage encapsulating the utilization of Zod within a generic helper function. Let’s examine a refined implementation:\n\n```ts\n// api/validator.ts\nimport { z, ZodIssue } from \"zod\";\n\ninterface ValidateConfig<T extends z.ZodTypeAny> {\n  dto: unknown;\n  schema: T;\n  schemaName: string;\n}\n\nexport function validateSchema<T extends z.ZodTypeAny>(\n  config: ValidateConfig<T>\n): z.infer<T> {\n  const { data, success, error } = config.schema.safeParse(config.dto);\n\n  if (success) {\n    return data;\n  } else {\n    captureError(`API Validation Error: ${config.schemaName}`, {\n      dto: config.dto,\n      error: error.message,\n      issues: error.issues,\n    });\n\n    throw error;\n  }\n}\n\nfunction captureError(message: string, extra = {}): void {\n  if (__DEV__) {\n    console.error(message, extra);\n  } else {\n    // TODO: report to Sentry/something else\n  }\n}\n```\n\nThis helper function takes a data transfer object (DTO), a Zod schema, and a schema name as arguments. It then validates the DTO against the schema and returns the validated data if validation succeeds. If validation fails, it logs an error message and throws an error.\n\nWith such a function ready, we only have to define a schema for each API response and use the helper function to validate the response data. Here’s an example of how that could look like:\n\n```ts\n// api/requests/v1/accountDetails/schema.ts\nimport { z } from \"zod\";\n\nexport const schema = z.object({\n  id: z.string().uuid(),\n  email: z.string().email(),\n  login: z.string(),\n  createdAt: z.string().datetime(),\n  deletedAt: z.string().datetime().nullable(),\n});\n```\n\n```ts\n// api/requests/v1/accountDetails/types.ts\nimport { z } from \"zod\";\nimport { schema } from \"./schema\";\n\nexport type AccountDetailsResponse = z.infer<typeof schema>;\nexport type AccountDetailsErrorResponse = Record<string, unknown>;\n```\n\n```ts {8-10}\n// api/requests/v1/accountDetails/request.ts\nimport { apiClient } from \"@/api/client\";\nimport { validateSchema } from \"@/api/validator\";\n\nimport { schema } from \"./schema\";\nimport { AccountDetailsResponse } from \"./types\";\n\nfunction validate(dto: unknown): AccountDetailsResponse {\n  return validateSchema({ dto, schema, schemaName: \"v1/account/details\" });\n}\n\nexport async function getAccountDetails(): Promise<AccountDetailsResponse> {\n  const response = await apiClient.get(\"/api/v1/account/details\");\n\n  return validate(response.data);\n}\n```\n\n## Conclusion\n\nAPI response validation is a critical aspect of building reliable and robust applications. Zod, with its TypeScript-first approach and expressive syntax, simplifies the process of defining and enforcing data schemas.\n\nBy incorporating Zod into your workflow, you can enhance the integrity of your APIs, catch potential issues early, and ensure that your application communicates seamlessly with external services.\n","excerpt":"When implementing applications, we often need to communicate with external services via APIs. In such cases, it’s crucial to ensure that the data received…","tableOfContents":{"items":[{"url":"#what-is-zod","title":"What is Zod"},{"url":"#why-use-zod","title":"Why use Zod"},{"url":"#how-to-use-zod","title":"How to use Zod"},{"url":"#conclusion","title":"Conclusion"}]},"fields":{"slug":"/blog/2023-11-19-api-response-validation-with-zod/","timeToRead":{"minutes":3.335,"words":667}},"frontmatter":{"title":"API Response validation with Zod","authors":["Bartosz Łaniewski"],"keywords":["JavaScript","TypeScript"],"language":"en","description":null,"dateCreated":"November 19, 2023","dateCreatedMeta":"2023-11-20 00:00:00 +0100","dateUpdated":"December 25, 2023","dateUpdatedMeta":"2023-12-26 00:00:00 +0100","datePublished":"November 19, 2023","datePublishedMeta":"2023-11-20 00:00:00 +0100"},"internal":{"contentFilePath":"/home/runner/work/bartozzz.github.io/bartozzz.github.io/content/blog/2023-11-19-api-response-validation-with-zod/index.md"}},{"id":"683df14a-e3e7-5b97-834b-d4071070c06a","body":"\n[Filler](https://filler.laniewski.me/) is the first mobile game I ever created with React Native. It started as an experiment to learn more about algorithms, animations, and the platform itself.\n\n## Introduction\n\nI initially created Filler when I was ~15 years old. The idea came up as I was thinking of simple projects I could work on to learn more about web development and data structures. It was later on that I learned there was already a similar (and quite popular back in the ’90s) game, called _\"Lights Out\"_.\n\n> Lights Out is an electronic game released by Tiger Electronics in 1995. The game consists of a 5 by 5 grid of lights. When the game starts, a random number or a stored pattern of these lights is switched on. Pressing any of the lights will toggle it and the adjacent lights. The goal of the puzzle is to switch all the lights off, preferably in as few button presses as possible. – [Wikipedia](https://en.wikipedia.org/wiki/Lights_Out_(game))\n\nThere are, however, a few differences between the original and my game. In Filler:\n1. grids can be of any size, not only $$5 \\times 5$$;\n2. the goal is to switch all the lights on, not off;\n\nThe technology stack is pretty standard for the React ecosystem:\n\n- [Expo](https://expo.dev/)\n- [TypeScript](https://www.typescriptlang.org/)\n- [React Navigation](https://reactnavigation.org/)\n- [Styled Components](https://styled-components.com/)\n\n## Development\n\n### Internationalization\n\nI used [`expo-localization`](https://docs.expo.dev/versions/latest/sdk/localization/) and [`i18n-js`](https://github.com/fnando/i18n-js) to localize my application. The internationalization setup is pretty straightforward:\n\n```ts\nimport * as Localization from \"expo-localization\";\nimport i18n from \"i18n-js\";\n\nimport en from \"./strings/en.json\";\nimport fr from \"./strings/fr.json\";\nimport pl from \"./strings/pl.json\";\n\ni18n.fallbacks = true;\ni18n.translations = { en, pl, fr };\ni18n.defaultLocale = \"en\";\ni18n.locale = Localization.locale;\n\nexport { i18n };\n```\n\n…then, I could simply import `i18n` and use it in the application as follows:\n\n```tsx\n<Button>{i18n.t(\"menu.campaignButton\")}</Button>\n```\n\nTo make my tests independent of the translations, I mocked the `i18n-js` library and made the `i18n.t` function return the translation key instead of the translation itself:\n\n```ts\njest.mock(\"i18n-js\", () => {\n  return {\n    ...jest.requireActual(\"i18n-js\"),\n    t: jest.fn((key) => key),\n  };\n});\n```\n\n…having that, I could safely update the copy without breaking the integration tests:\n\n```tsx\nit(\"should reset the board on ’Reset’ button click\", () => {\n  const view = render(<Game />);\n\n  fireEvent.press(view.getByText(\"header.resetBtn\"));\n  // …\n});\n```\n\nI was not afraid to break anything in the user interface because my application contains visual regression tests. It allows me to ensure that my application appears to the end-user as it was originally intended to and I can catch visual regressions with ease.\n\n<Newsletter />\n\n### Animations\n\nI used [`react-native-reanimated`](https://github.com/software-mansion/react-native-reanimated) to create all animations in the game. The main reason behind this choice was that the animations run on the native thread – it’s a great animation library performance-wise. It comes with an imperative and a declarative API.\n\n#### Imperative API\n\nI used the imperative functions and hooks for the `GridCell` component. I wanted to interpolate between two colors based on the `checked` prop. It was possible thanks to the `interpolateColor` helper:\n\n```tsx {2, 5-11, 15}\nfunction GridCell({ checked }: { checked: boolean }) {\n  const colorProgress = useSharedValue(checked ? 1 : 0);\n\n  // Interpolate between `empty` and `checked` color based on progress:\n  const animatedStyles = useAnimatedStyle(() => ({\n    backgroundColor: interpolateColor(\n      colorProgress.value,\n      [0, 1],\n      [theme.emptyCellColor, theme.checkedCellColor]\n    ),\n  }), [theme, colorProgress]);\n\n  // Change progress to 0-1 on `checked` change:\n  React.useEffect(() => {\n    colorProgress.value = withTiming(checked ? 1 : 0);\n  }, [checked, colorProgress]);\n\n  return <Cell style={animatedStyles} />\n}\n```\n\n#### Declarative API\n\nThere’s also a higher-level API that I used to progressively reveal content on the success screen. I didn’t need anything fancy here, just some entering animations with delays and the declarative API does a great job for such things:\n\n```tsx {6, 10, 14}\nfunction ScoreStars({ score }: { score: number }) {\n  const delay = 250;\n\n  return (\n    <Stars>\n      <Animated.View entering={Swing.delay(delay * 0)}>\n        {score < 1 ? <GrayStar /> : <GoldStar />}\n      </Animated.View>\n\n      <Animated.View entering={Swing.delay(delay * 1)}>\n        {score < 2 ? <GrayStar /> : <GoldStar />}\n      </Animated.View>\n\n      <Animated.View entering={Swing.delay(delay * 2)}>\n        {score < 3 ? <GrayStar /> : <GoldStar />}\n      </Animated.View>\n    </Stars>\n  );\n};\n```\n\n…where `Swing` is a custom [keyframe](https://docs.swmansion.com/react-native-reanimated/docs/2.x/api/LayoutAnimations/keyframeAnimations/) I created:\n\n```tsx\nconst Swing = () =>\n  new Keyframe({\n    0: { transform: [{ rotate: \"0deg\" }] },\n    20: { transform: [{ rotate: \"15deg\" }] },\n    40: { transform: [{ rotate: \"-10deg\" }] },\n    60: { transform: [{ rotate: \"5deg\" }] },\n    80: { transform: [{ rotate: \"-5deg\" }] },\n    100: { transform: [{ rotate: \"0deg\" }] },\n  });\n```\n\n### Monetization\n\nAfter the gameplay was implemented, I started working on integrating ads into the application using Google’s AdMob platform. The monetization model is pretty standard in the mobile industry. I decided to show:\n- an Interstitial Ad when the user completes a level (cap at 1 impression every 5 minutes per user);\n- a Rewarded Ad to unlock the solution w/ solver.\n\nI used [`react-native-google-mobile-ads`](https://github.com/invertase/react-native-google-mobile-ads) (and had a chance to contribute a little bit to the library as well!) to implement the advertising.\n\n#### Interstitial Ad\n\nI created a hook to easily check whether the advertisement has been watched or not.\n\n```tsx\nfunction useInterstitialAd() {\n  const { isLoaded, isClosed, error, load, show } = nativeUseInterstitialAd(\n    \"<AD_UNIT_ID>\",\n    {\n      requestNonPersonalizedAdsOnly: true,\n    }\n  );\n\n  const isError = error !== undefined;\n  const isAdWatched = isClosed || isError;\n\n  // Start loading the interstitial straight away:\n  React.useEffect(() => {\n    load();\n  }, [load]);\n\n  // Show the interstitial once loaded:\n  React.useEffect(() => {\n    if (isLoaded) {\n      show();\n    }\n  }, [isLoaded, show]);\n\n  return { isAdWatched };\n}\n```\n\n…then, I could very simply disable the \"Next level\" button until the ad has been watched:\n\n```tsx\nconst { isAdWatched } = useInterstitialAd();\n\n<Button disabled={!isAdWatched} onPress={handleExit}>\n  Next level\n</Button>\n```\n\n#### Rewarded Ad\n\nRewarded ads need a trigger and an explicit user interaction to show. I decided to go with a React Render Props pattern for a nice DX:\n\n```tsx\n<RewardedAd onSuccess={showSolution}>\n  {({ trigger, isAdLoading }) => (\n    <ActionButton onPress={trigger} processing={isAdLoading}>\n      Show solution\n    </ActionButton>\n  )}\n</RewardedAd>\n```\n\n`RewardedAd` hides a lot of boilerplate, but basically, it listens for events and handles the various errors that can occur.\n\n## Challenges\n\n### Permissions\n\n<Alert type=\"warning\">\n\nBy default, Expo adds a lot of unnecessary permission which can discourage the user from installing your application.\n</Alert>\n\nOnce released on Google Play, I noticed that the app had unnecessary permission listed. It required pretty much every permission available but needed none to work. To remove unused permissions, I had to modify `android/app/src/main/AndroidManifest.xml` as follows (note the `tools:node=\"remove\"` on `uses-permission`):\n\n```xml\n<manifest xmlns:tools=\"http://schemas.android.com/tools\" xmlns:android=\"http://schemas.android.com/apk/res/android\">\n  <uses-permission android:name=\"android.permission.VIBRATE\" />\n  <uses-permission android:name=\"android.permission.INTERNET\" />\n  <uses-permission tools:node=\"remove\" android:name=\"android.permission.MODIFY_AUDIO_SETTINGS\" />\n  <uses-permission tools:node=\"remove\" android:name=\"android.permission.READ_EXTERNAL_STORAGE\" />\n  <uses-permission tools:node=\"remove\" android:name=\"android.permission.READ_PHONE_STATE\" />\n  <uses-permission tools:node=\"remove\" android:name=\"android.permission.RECORD_AUDIO\" />\n  <uses-permission tools:node=\"remove\" android:name=\"android.permission.SYSTEM_ALERT_WINDOW\" />\n  <uses-permission tools:node=\"remove\" android:name=\"android.permission.WRITE_EXTERNAL_STORAGE\" />\n</manifest>\n```\n\n### Performance\n\nI use my old [Asus ZenFone 3 Max 5.2](https://www.gsmchoice.com/en/catalogue/asus/zenfone3maxzc520tl/) as a benchmark – if a game works nicely on this device, I can sleep soundly because it means it will run on pretty much anything. My aim I always to get a stable 60 FPS for a nice user experience.\n\nIt was quite hard to achieve at first for several reasons:\n1. **Initially, I used [`react-native-animatable`](https://github.com/oblador/react-native-animatable) for animations:** it had noticeably worse performance than `react-native-reanimated`;\n2. **There were some redundant re-renders:** once I memorized some expensive components and calculation results, it improved the performance;\n3. **I was using JSC instead of [Hermes](https://engineering.fb.com/2019/07/12/android/hermes/):** once I migrated to Hermes, the performance improved greatly. Also, <abbr title=\"Time to Interaction\">TTI</abbr>, application size and memory utilization decreased a lot;\n\nIt turned out that React Native with Hermes can perform well enough to provide a nice UX, even on my old phone.\n\n### Sounds\n\nThere’s an issue with playing the same [`Audio`](https://docs.expo.dev/versions/latest/sdk/audio/) multiple times: the sound works well the first time, but the other times it seems that the sound isn’t playing from the start but has a shift of some milliseconds.\n\nThe solution I use is to preload multiple copies of [`Audio`](https://docs.expo.dev/versions/latest/sdk/audio/) and play the next sample when needed. My implementation looks as follows:\n\n```ts\nimport { Audio } from \"expo-av\";\nimport { AVPlaybackSource } from \"expo-av/build/AV\";\n\nclass Sound {\n  static COPIES = 3;\n  static INDEX = 0;\n  static assets: Record<string, Audio.Sound> = {};\n\n  static loadAsync(library: Record<string, AVPlaybackSource>) {\n    const promisesForCopies = Object.entries(library).flatMap(\n      ([name, path]: [string, AVPlaybackSource]) => {\n        // Make n = Sound.COPIES copies:\n        return Array.from(Array(Sound.COPIES)).map((_, i) => {\n          const soundNameWithIndex = `${name}-${i}`;\n\n          Sound.assets[soundNameWithIndex] = new Audio.Sound();\n          return Sound.assets[soundNameWithIndex].loadAsync(path);\n        });\n      }\n    );\n\n    return Promise.all(promisesForCopies);\n  }\n\n  static async play(name: string, volume = 1) {\n    try {\n      Sound.INDEX = (Sound.INDEX + 1) % Sound.COPIES;\n\n      const soundNameWithIndex = `${name}-${Sound.INDEX}`;\n      const soundSample = Sound.assets[soundNameWithIndex];\n\n      if (soundSample) {\n        await soundSample.setVolumeAsync(volume);\n        await soundSample.playFromPositionAsync(0);\n      } else {\n        throw new Error(`Sound ${name} does not exist`);\n      }\n    } catch (error) {\n      // Silent error…\n    }\n  }\n}\n```\n\n### Solver\n\nI wanted to create a solver to monetize the game. It turned out to be quite a popular problem with a lot of resources online, so I won’t go into much detail. It just required a bit of linear algebra.\n\nA board can be modeled mathematically as a vector over $$\\mathbb{F}_2$$, a [field](https://en.wikipedia.org/wiki/GF(2)) containing only the elements 0 and 1 (for light on and off respectively). We can write each possible board position and each possible move as a vector over $$\\mathbb{F}_2$$. That means that:\n- pressing a cell an even number of times has no effect;\n- the order in which we press the cells does not matter;\n\nTo solve the board, we need to find a combination of these move vectors which adds up to give the current board, since that will cancel with the board, turning all of the lights on. There is a systematic way of solving this kind of vector problem called [Gaussian Elimination](https://en.wikipedia.org/wiki/Gaussian_elimination).\n\n```ts\nfunction solve(width: number, height: number, state: boolean[]): number[] {\n  const moveVector = buildMoveVector(width, height);\n  const moveMatrix = buildMoveMatrix(moveVector, state);\n  const solution = getLastRow(rref(moveMatrix));\n\n  return solution;\n}\n```\n\nA nice video explaining this in detail can be found [here](https://www.youtube.com/watch?v=oCHCD_-nhg4).\n\n## Conclusion\n\nIt was a fun experience to rebuild the same game several years later after gathering all of my commercial experience and still being able to learn new things along the journey. So far, I’ve got 200+ downloads and generated $0.20 in ad revenue, but hey, the learnings are priceless!\n","excerpt":"Filler is the first mobile game I ever created with React Native. It started as an experiment to learn more about algorithms, animations, and the platform…","tableOfContents":{"items":[{"url":"#introduction","title":"Introduction"},{"url":"#development","title":"Development","items":[{"url":"#internationalization","title":"Internationalization"},{"url":"#animations","title":"Animations"},{"url":"#monetization","title":"Monetization"}]},{"url":"#challenges","title":"Challenges","items":[{"url":"#permissions","title":"Permissions"},{"url":"#performance","title":"Performance"},{"url":"#sounds","title":"Sounds"},{"url":"#solver","title":"Solver"}]},{"url":"#conclusion","title":"Conclusion"}]},"fields":{"slug":"/blog/2022-06-27-case-study-filler/","timeToRead":{"minutes":8.53,"words":1706}},"frontmatter":{"title":"Case study: Filler (a React Native game)","authors":["Bartosz Łaniewski"],"keywords":["Case Study","Gamedev","React Native"],"language":"en","description":null,"dateCreated":"June 26, 2022","dateCreatedMeta":"2022-06-27 00:00:00 +0100","dateUpdated":"December 25, 2023","dateUpdatedMeta":"2023-12-26 00:00:00 +0100","datePublished":"June 26, 2022","datePublishedMeta":"2022-06-27 00:00:00 +0100"},"internal":{"contentFilePath":"/home/runner/work/bartozzz.github.io/bartozzz.github.io/content/blog/2022-06-27-case-study-filler/index.md"}},{"id":"2b4449d8-704e-59c2-98a4-5640ac88e48f","body":"\n[Tilt Copters] is a relatively simple game created with [PixiJS] and Expo. This is a project I’ve started to learn more about porting web libraries to React Native but also about game architecture and monetization.\n\n## Introduction\n\nTilt Copters is a casual endless game. The user picks the character he wishes to pilot and can explore various maps. The character can be moved by tilting the device. The user has to avoid obstacles and the higher he gets, the faster and more challenging the game becomes.\n\nTechnology stack:\n\n- [Expo](https://expo.dev/)\n- [TypeScript](https://www.typescriptlang.org/)\n- [React Navigation](https://reactnavigation.org/)\n- [Styled Components](https://styled-components.com/)\n- [PixiJS] with [my port](https://github.com/Bartozzz/expo-pixi) of the library\n- [Redux Toolkit](https://redux-toolkit.js.org/)\n- [Zustand](https://github.com/pmndrs/zustand)\n\n## Development\n\nI am well aware that React Native might not be ready for game development just yet. I picked it out of curiosity – I wanted to see where the limits of this technology are.\n\nNevertheless, React Native has its benefits. The main advantage over native solutions is that it’s easy to make cross-platform applications for mobile, desktop, and web while still having the option to interop native code when necessary. It has an established ecosystem, community and is backed by a lot of big companies (industry momentum).\n\n### Architecture\n\nLet’s start by analyzing the elements and features that we have in the game. We have:\n- a character and a map defined by a background, pipes, and coins;\n- a controller system that hooks to the device accelerometer;\n- a collision system that handles pipes and coin collisions;\n\n#### Game Manager\n\nThe Game Manager is a [mediator](https://refactoring.guru/design-patterns/mediator) and serves as an aggregator for the Game Objects.\n\n```ts\nexport class GameManager {\n  public constructor({ context }: EngineConfiguration) {\n    this.application = new PIXI.Application({ context });\n\n    // Updates:\n    this.ticker.add(() => {\n      if (this.store.state === \"isPlaying\") {\n        // Updates:\n        this.background.update(this.speed);\n        this.character.update(this.speed);\n        this.pipes.forEach((pipe) => pipe.update(this.speed));\n        this.coins.forEach((coin) => coin.update(this.speed));\n\n        // Collision check:\n        this.obstaclesManager.check();\n\n        // Speed increase:\n        this.speed += configuration.game.acceleration;\n      }\n    });\n\n    // Controls:\n    this.controlManager.subscribe(ControlManager.MOVE, (data: number) => {\n      this.character.move(data);\n    });\n\n    // Collisions:\n    this.obstaclesManager.subscribe(ObstaclesManager.PIPE_COLLISION, () => {\n      this.lose();\n    });\n    this.obstaclesManager.subscribe(ObstaclesManager.PIPE_PASSED, (pipe) => {\n      pipe.score();\n      this.store.incrementScore();\n    });\n    this.obstaclesManager.subscribe(ObstaclesManager.COIN_COLLISION, (coin) => {\n      coin.score();\n      this.store.incrementCoins();\n    });\n  }\n\n  public initialize(gameConfig: GameConfiguration) {\n    // …\n  }\n  public reset() {\n    // …\n  }\n  public destroy() {\n    // …\n  }\n\n  public prepare() {\n    this.store.setState(\"isIdle\");\n    this.application.start();\n  }\n  public play() {\n    this.store.setState(\"isPlaying\");\n    this.application.start();\n  }\n  public lose() {\n    this.store.setState(\"isGameOver\");\n    this.application.stop();\n  }\n}\n\n```\n\n#### Game Objects\n\nThe Game Objects describe elements in the game world (character, background, pipe, coin). All these elements are implementing the `GameObject` interface:\n\n```ts\nexport interface GameObject {\n  update(delta: number): void;\n  destroy(): void;\n  getBoundingBoxes(): BoundingBox[];\n}\n```\n\n### Navigation\n\nI used [`@react-navigation/stack`](https://reactnavigation.org/docs/stack-navigator/) to handle all in-game navigation. I created [custom interpolators](https://reactnavigation.org/docs/stack-navigator/#animations) to give the user an illusion that the entire game is one big canvas just sliding down or up based on the view that we want to show.\n\nBelow is the code that I used to customize the transition when navigating from the menu to the shop and vice-versa:\n\n```ts\nexport function forShopInterpolator({\n  index,\n  current,\n  next,\n  inverted,\n  layouts: { screen },\n}: StackCardInterpolationProps): StackCardInterpolatedStyle {\n  const isFirst = index === 0;\n\n  const progress = add(\n    current.progress.interpolate({\n      inputRange: [0, 1],\n      outputRange: [0, 1],\n      extrapolate: \"clamp\",\n    }),\n    next\n      ? next.progress.interpolate({\n          inputRange: [0, 1],\n          outputRange: [0, 1],\n          extrapolate: \"clamp\",\n        })\n      : 0\n  );\n\n  const translateY = multiply(\n    progress.interpolate({\n      inputRange: [0, 1, 2],\n      outputRange: [\n        screen.height,\n        isFirst ? 0 : 0,\n        isFirst ? -screen.height : 0,\n      ],\n    }),\n    inverted\n  );\n\n  return {\n    cardStyle: {\n      overflow: \"hidden\",\n      transform: [{ translateY }],\n    },\n  };\n}\n```\n\n<Newsletter />\n\n### Responsiveness\n\nUnlike most game engines, `pixi.js` does not handle multiple resolutions out of the box. You’ll have to manually stretch the game viewport to match the device screen size.\n\nMy approach is to use a single base resolution and then fit it into everything else. The one I picked is 375x812pt (iPhone X). Think of this setting as the \"design size\", i.e. the size of the area that you work with when creating textures.\n\n```ts\nimport { Dimensions } from \"react-native\";\n\nconst window = Dimensions.get(\"window\");\n\nexport const targetWidth = 375;\nexport const targetHeight = 812;\nexport const scale = (window.width * window.scale) / targetWidth;\n\nexport const canvas = {\n  width: targetWidth,\n  height: targetHeight,\n  scale: scale,\n};\n```\n\nThen, I just had to set the [`PIXI.Application`](https://pixijs.download/v4.8.9/docs/PIXI.Application.html#Application) `width`, `height` and `resolution` as follows:\n\n```ts {7-9}\nexport class GameManager {\n  private application!: PIXI.Application;\n\n  public constructor({ context }: EngineConfiguration) {\n    this.application = new PIXI.Application({\n      context,\n      width: configuration.canvas.width,\n      height: configuration.canvas.height,\n      resolution: configuration.canvas.scale,\n    });\n  }\n}\n```\n\n`resolution` will stretch the canvas to fit the whole screen while maintaining aspect ratios no matter the resolution. The scene is rendered and then scaled to fit the screen.\n\n### State management\n\nI used [zustand](https://github.com/pmndrs/zustand) for game state management. It is a barebones state-management solution using simplified flux principles. It’s really easy to use and framework agnostic (no context providers are necessary), so I can use it in React (UI) and game managers (logic). My game store looks as follows:\n\n```ts\nimport create from \"zustand\";\nimport createVanilla from \"zustand/vanilla\";\nimport { combine } from \"zustand/middleware\";\n\ninterface State {\n  state: \"isIdle\" | \"isPlaying\" | \"isGameOver\";\n  score: number;\n  coins: number;\n}\n\nconst initialState: State = {\n  state: \"isIdle\",\n  score: 0,\n  coins: 0,\n};\n\nexport const gameStore = createVanilla(\n  combine(initialState, (set) => ({\n    reset: () => set(initialState),\n    setState: (payload: State[\"state\"]) =>\n      set((state) => ({ state: payload })),\n    incrementScore: (payload = 1) =>\n      set((state) => ({ score: Math.max(0, state.score + payload) })),\n    incrementCoins: (payload = 1) =>\n      set((state) => ({ coins: Math.max(0, state.coins + payload) })),\n  }))\n);\n\nexport const useGameStore = create(gameStore);\n```\n\n#### Usage in managers\n\n```ts {2-4, 8, 14, 18}\nexport class GameManager {\n  private get store() {\n    return gameStore.getState();\n  }\n\n  public constructor({ context }: EngineConfiguration) {\n    this.ticker.add(() => {\n      if (this.store.state === \"isPlaying\") {\n        // Do the updates…\n      }\n    });\n\n    this.obstaclesManager.subscribe(ObstaclesManager.PIPE_PASSED, () => {\n      this.store.incrementScore();\n    });\n\n    this.obstaclesManager.subscribe(ObstaclesManager.COIN_COLLISION, () => {\n      this.store.incrementCoins();\n    });\n  }\n}\n```\n\n#### Usage in React\n\n```tsx {2}\nexport function GameScore() {\n  const score = useGameStore((state) => state.score);\n\n  return <Text size=\"lg\">{score}</Text>;\n}\n```\n\n<Alert type=\"info\">\n\n  I used [Redux Toolkit](https://redux-toolkit.js.org/) for the user state (i.e. purchased items) and [`redux-persist`](https://github.com/rt2zz/redux-persist) for persistence. There are no particular reasons why I used Redux over Zustand or any other solution.\n</Alert>\n\n## Challenges\n\n### Expo and libraries\n\nThere’s an official library called [`expo-pixi`](https://github.com/expo/expo-pixi) originally developed by Evan Bacon. This is the first search result when looking for [PixiJS] for Expo/React Native. I tried using this library but quickly abandoned it because of plenty of issues it has. Instead, I created my port with better compatibility. It can be found on [`Bartozzz/expo-pixi`](https://github.com/Bartozzz/expo-pixi).\n\n#### Issue #1: incompatible with Expo 43 ([#221](https://github.com/expo/expo-pixi/issues/221))\n\n`expo-pixi` uses [`expo-asset-utils`](https://github.com/expo/expo-asset-utils) which is incompatible with Expo SDK 43 and above. This is because Expo SDK 43 [deprecated the `react-native-unimodules` package](https://blog.expo.dev/whats-new-in-expo-modules-infrastructure-7a7cdda81ebc):\n\n> The `react-native-unimodules` package is deprecated as of SDK 43, and the module system and autolinking implementation now live in the expo package instead.\n\nThe solution was to migrate from [`expo-asset-utils`](https://github.com/expo/expo-asset-utils) to [`expo-asset`](https://docs.expo.dev/versions/latest/sdk/asset/):\n\n```diff\n-import { resolveAsync } from \"expo-asset-utils\";\n+import { Asset } from \"expo-asset\";\n\nconst textureFromExpoAsync = async resource => {\n- const asset = await resolveAsync(resource);\n+ const asset = await Asset.fromModule(resource).downloadAsync();\n\n  return PIXI.Texture.from(asset);\n}\n```\n\n#### Issue #2: invalid dependencies ([#156](https://github.com/expo/expo-pixi/issues/156))\n\n1. `expo-pixi` does not have a locked-in version of `pixi-filters`. It downloads the latest version which is incompatible with pixi-js V4;\n2. `expo-pixi` requires `expo-gl` V4, which is incompatible with Expo SDK 40 and above;\n\nTo fix those issues, I updated the dependencies as follows:\n\n```diff\n{\n  \"dependencies\": {\n-   \"pixi-filters\": \"*\",\n+   \"pixi-filters\": \"2.7.1\",\n-   \"pixi.js\": \"^4.7.0\"\n+   \"pixi.js\": \"latest-4.x\"\n  },\n  \"peerDependencies\": {\n-   \"expo-gl\": \"~4.0.0\"\n+   \"expo-gl\": \"*\"\n  }\n}\n```\n\n#### Issue #3: side effects and library overwriting model\n\n`expo-pixi` overwrites `pixi.js` methods in a quite ugly way. It mutates the PIXI instance:\n\n```ts\nPIXI = {\n  ...PIXI,\n  Application: ExpoPIXIApplication,\n  Texture: {\n    ...PIXI.Texture,\n    from: (...props) => { /* … */ },\n    fromExpoAsync: textureFromExpoAsync,\n  },\n  Sprite: {\n    ...PIXI.Sprite,\n    fromExpoAsync: spriteFromExpoAsync,\n    from: (...props) => { /* … */ },\n  }\n}\n```\n\nThere are several issues with this approach:\n1. This is causing side effects, as PIXI is declared in the global scope;\n2. There was a mix of web-only and native-only code in a single file;\n\nTo solve the first issue, my approach was to simply extend PIXI classes and re-export new PIXI objects:\n\n```ts\nimport * as filters from \"pixi-filters\";\nimport * as PIXIInstance from \"pixi.js\";\n\nclass PIXIApplication extends PIXIInstance.Application {\n  // …\n}\n\nclass PIXISprite extends PIXIInstance.Sprite {\n  static from(asset) {\n    // …\n  }\n}\n\nclass PIXITexture extends PIXIInstance.Texture {\n  static from(asset) {\n    // …\n  }\n}\n\nexport const PIXI = {\n  ...PIXIInstance,\n  filters: {\n    ...PIXIInstance.filters,\n    ...filters,\n  },\n  Application: PIXIApplication,\n  Texture: PIXITexture,\n  Sprite: PIXISprite,\n};\n```\n\nWith this approach, I could safely remove the `sideEffects` flag from `package.json`:\n\n```diff\n{\n  \"name\": \"expo-pixi\",\n- \"sideEffects\": true,\n}\n```\n\nTo solve the second issue, I simply moved the web code to `pixi.ts`, and the native code to `pixi.native.ts`. This is described in detail in [React Native documentation: Platform-specific extensions](https://reactnative.dev/docs/platform-specific-code#platform-specific-extensions):\n\n> You can also use the `.native.js` extension when a module needs to be shared between NodeJS/Web and React Native but it has no Android/iOS differences. This is especially useful for projects that have common code shared among React Native and ReactJS.\n\n#### Issue #4: assets were not properly bundled on production build ([#66](https://github.com/expo/expo-pixi/issues/66), [#92](https://github.com/expo/expo-pixi/issues/92), [#103](https://github.com/expo/expo-pixi/issues/103))\n\n<Alert type=\"warning\">\n\n  This was particularly hard to debug because it only happens on release (production) Android builds. This issue does not happen on development and Web/iOS platforms.\n</Alert>\n\nThere are issues with `expo-gl` where `.jpg` and `.png` textures would not load in Android release variants. This is an issue (actually, several issues) with Expo and thus it was quite hard to fix it in the package itself. The fixes consist of several workarounds described below:\n\n##### Invalid file scheme\n\nWhen built as APK, the image asset resolves to something like:\n\n```\nfile:/data/user/0/…/.expo-internal/some-hash.png\n```\n\nThe problem is that [`expo-gl#loadImage`](https://github.com/expo/expo/blob/master/packages/expo-gl-cpp/cpp/EXGLImageUtils.cpp#L126) expects `file://` scheme and not `file:` (note the missing slashes). To solve this issue, we have to manually add the slashes to `asset.localUri`s, as follows:\n\n```ts\n// An asset uri might start with `file:` and not `file://`.\n// `expo-gl` expects a texture asset to have the slashes. Enforce the slashes.\nfunction fixFileUri(uri: string) {\n  // https://github.com/expo/expo/blob/master/packages/expo-gl-cpp/cpp/EXGLImageUtils.cpp#L126\n  return uri.startsWith(\"file:\") && !uri.startsWith(\"file://\")\n    ? \"file://\" + uri.substring(5)\n    : uri;\n}\n\nasync function textureFromAssetAsync(resource: string | number) {\n  const asset = await Asset.fromModule(resource).downloadAsync();\n  asset.localUri = fixFileUri(asset.localUri!);\n\n  return PIXITexture.from(asset as any);\n}\n```\n\n##### Invalid path for images\n\nWhen you [bundle assets for your Android APK](https://developer.android.com/guide/topics/resources/providing-resources), the assets go to the `res` folder, but the subfolder they end up is dependent on the resource type. Bitmap files (`.png`, `.jpg`, `.gif`, etc.) or XML files that are compiled into drawable resource subtypes go to `res/drawables` directory.\n\nThe issue is that in production, images are moved to the `res/drawables` directory (as you would expect) but `expo-file-system` [`FileSystem#downloadAsync`](https://github.com/expo/expo/blob/main/packages/expo-file-system/android/src/main/java/expo/modules/filesystem/FileSystemModule.kt#L911=) only checks the `raw` directory! Because of that, I was unable to load textures for `expo-pixi` on Android.\n\nI don’t know any viable workaround for this issue. What worked for me was changing the image extensions to `.xjpg` and `.xpng`. I also had to update the `textureFromAssetAsync` to change `asset.type` to the correct extension and recalculate `asset.width` and `asset.height` as follows:\n\n```ts {22,24-26}\n// https://github.com/expo/expo/blob/main/packages/expo-asset/src/ImageAssets.ts\nfunction getImageInfo(url: string): Promise<{\n  width: number;\n  height: number;\n}> {\n  return new Promise((resolve, reject) => {\n    const img = new Image();\n    img.onerror = reject;\n    img.onload = () => {\n      resolve({\n        width: img.width,\n        height: img.height,\n      });\n    };\n    img.src = url;\n  });\n}\n\nasync function textureFromAssetAsync(resource: string | number) {\n  const asset = await Asset.fromModule(resource).downloadAsync();\n  asset.localUri = fixFileUri(asset.localUri!);\n  asset.type = asset.type.replace(\"x\", \"\"); // xpng => png, xjpg => jpg\n\n  const { width, height } = await getImageInfo(asset.localUri);\n  asset.width = width;\n  asset.height = height;\n\n  return PIXITexture.from(asset as any);\n}\n```\n\nI also needed to update `metro.config.js` to allow `.xjpg` and `.xpng` extensions:\n\n```ts\nconst { getDefaultConfig } = require(\"@expo/metro-config\");\nconst defaultConfig = getDefaultConfig(__dirname);\n\n// Added .xjpg and .xpng extensions for sprites:\ndefaultConfig.resolver.assetExts.push(\"xjpg\");\ndefaultConfig.resolver.assetExts.push(\"xpng\");\n\nmodule.exports = defaultConfig;\n```\n\n### Game performance\n\nMy aim I always to get at least a stable 60 FPS on all of the devices I have. Here are the results:\n\n- [iPhone X](https://www.gsmchoice.com/en/catalogue/apple/iphonex/): 60 FPS;\n- [iPhone 13 Pro](https://www.gsmchoice.com/en/catalogue/apple/iphone13pro/): 60 FPS;\n- [Samsung S8](https://www.gsmchoice.com/en/catalogue/samsung/galaxys8/): 50-60 FPS;\n- [Asus ZenFone 3 Max 5.2](https://www.gsmchoice.com/en/catalogue/asus/zenfone3maxzc520tl/): 40-60 FPS.\n\nAndroid phones have some troubles with garbage collection and there’s a ~10 FPS performance drop when going back and forth from the menu to the game screen.\n\n### React Native performance\n\nReact Native is performant overall and its capabilities are more than enough for standard user interfaces. However, when combined with game rendering and intensive processing in the game loop, you might want to limit React renders.\n\nI wanted to show the user the distance he flew during the gameplay. The natural place I wanted to put the score was the navigation bar from React Navigation but it resulted in a 10 FPS performance drop. Two options were presented:\n\n1. I could render the score in a custom component, or,\n2. I could render the score on the canvas;\n\nThe second solution was not possible to implement because `expo-pixi` has [no support for rendering text on the canvas](https://github.com/expo/expo-pixi/issues/20). Moving the score to a custom component had no big impact on the performance, but required some code to support notch on Apple devices. Later on, I decided to display the number of pipes passed instead and I was able to use the React Navigation back.\n\n### Android differences\n\n<Alert type=\"warning\">\n\n  Always test your application on all platforms before release. React Native offers cross-platform compatibility but some native differences have to be overcome manually.\n</Alert>\n\nSome of the deviations were already described in [Expo and libraries](#expo-and-libraries) but there are more! The main differences between Android and other platforms are:\n\n- **Difference in default UI/UX:** by default the stack navigator is configured to have the familiar iOS and Android look & feel: new screens slide in from the right on iOS and use OS default animation on Android. There are also visual differences that need to be patched to provide similar game UI/UX across platforms;\n- **No full fonts support:** `font-weight` and `font-style` [are not supported](https://stackoverflow.com/questions/38815234/how-to-add-fonts-for-different-font-weights-for-react-native-android-project/38820631#38820631). You have to load all the font variants as separate fonts with a different `font-family` name;\n- **No full shadows support:** Android does not have native support for CSS-like shadows. You have to use the [`elevation`](https://reactnative.dev/docs/view-style-props#elevation-android) property or 3rd party libraries like [`react-native-shadow`](https://www.npmjs.com/package/react-native-shadow-2);\n- **Poor styling support**: for example, when making a text outline using `text-shadow`, we have to keep a small blur radius because Android won’t render it at all when it’s set to 0 (`text-shadow: 0 2px 0.00001px black`);\n- **Inconsistent API:** on Android devices, the accelerometer data is reversed and we have to normalize it before usage:\n    ```ts\n    import { Accelerometer } from \"expo-sensors\";\n    import { Platform } from \"react-native\";\n    import { PubSub } from \"../helpers/PubSub\";\n\n    export class ControlManager extends PubSub {\n      static MOVE = \"MOVE\";\n\n      public register() {\n        Accelerometer.addListener((accelerometerData) => {\n          const data =\n            // For some reason on Android the signs are flipped:\n            Platform.OS === \"android\"\n              ? -accelerometerData.x\n              : accelerometerData.x;\n\n          this.publish(ControlManager.MOVE, data);\n        });\n      }\n\n      public destroy() {\n        Accelerometer.removeAllListeners();\n      }\n    }\n    ```\n\n## Conclusion\n\nMaking a simple game was a great way to learn the Expo internals and limitations, but `expo-pixi` it’s not the best tool for the job:\n- there is a lack of support when it comes to `expo-pixi`;\n- there are plenty of bugs, especially on Android devices;\n- the performance is not great overall;\n\nBecause of that, I started working on my game library for React Native that uses [`react-native-skia`](https://github.com/Shopify/react-native-skia), a high-performance React Native Graphics library under the hood.\n\n[Tilt Copters]: https://tiltcopters.laniewski.me\n[PixiJS]: https://pixijs.com/\n","excerpt":"Tilt Copters is a relatively simple game created with PixiJS and Expo. This is a project I’ve started to learn more about porting web libraries to React…","tableOfContents":{"items":[{"url":"#introduction","title":"Introduction"},{"url":"#development","title":"Development","items":[{"url":"#architecture","title":"Architecture"},{"url":"#navigation","title":"Navigation"},{"url":"#responsiveness","title":"Responsiveness"},{"url":"#state-management","title":"State management"}]},{"url":"#challenges","title":"Challenges","items":[{"url":"#expo-and-libraries","title":"Expo and libraries"},{"url":"#game-performance","title":"Game performance"},{"url":"#react-native-performance","title":"React Native performance"},{"url":"#android-differences","title":"Android differences"}]},{"url":"#conclusion","title":"Conclusion"}]},"fields":{"slug":"/blog/2022-06-11-case-study-tilt-copters/","timeToRead":{"minutes":13.09,"words":2618}},"frontmatter":{"title":"Case study: Tilt Copters (a React Native game)","authors":["Bartosz Łaniewski"],"keywords":["Case Study","Gamedev","React Native"],"language":"en","description":null,"dateCreated":"June 10, 2022","dateCreatedMeta":"2022-06-11 00:00:00 +0100","dateUpdated":"December 25, 2023","dateUpdatedMeta":"2023-12-26 00:00:00 +0100","datePublished":"June 10, 2022","datePublishedMeta":"2022-06-11 00:00:00 +0100"},"internal":{"contentFilePath":"/home/runner/work/bartozzz.github.io/bartozzz.github.io/content/blog/2022-06-11-case-study-tilt-copters/index.md"}},{"id":"f8f52dff-a71e-5156-b69e-7a11bd3d8c00","body":"\nMost of the designs are rarely built with user preferences in mind, it is the appearance that matters after all! Few people realize the way you respect and adapt the design to users’ preferences can have an impact on how accessible your product is. In this article, I’ll list out few things to keep in mind when developing inclusive designs.\n\n## Prevent animations if a user prefers reduced motion\n\n> Some users experience distraction or nausea from animated content. For example, if scrolling a page causes elements to move (other than the essential movement associated with scrolling) it can trigger vestibular disorders. ~ [W3 WCAG](https://www.w3.org/WAI/WCAG21/Techniques/css/C39)\n\n[The `prefers-reduced-motion` media query](https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-reduced-motion) can be used to detect if the user prefers to limit the amount of non-essential motions. The user can indicate this preference in their operating system. The following CSS code can be applied to disable that motion for users who request it:\n\n```css\n@media (prefers-reduced-motion: reduced) {\n  .element {\n    /* CSS to disable motion goes here */\n    animation: none;\n  }\n}\n```\n\nI prefer to go the other way around and enable animations for users who have made no preference known to the system.\n\n```css\n@media (prefers-reduced-motion: no-preference) {\n  .element {\n    /* CSS to enable motion goes here */\n    transition: all 0.2s ease;\n  }\n}\n```\n\nKeep in mind that reduced motion preference does not only apply to animations – it can apply to transitions but also to GIFs or videos with auto-play. [Val Head created a great article](https://alistapart.com/article/designing-safer-web-animation-for-motion-sensitivity/#section3) in which he points out how to identify potentially triggering animations.\n\n## Size content based on the user’s preferred font size\n\nUsers can adjust the preferred font size in the browser setting. The browser font size can be read by using percentage units – setting `font-size: 100%` will make your text 100% of the base font size set in the browser by the user:\n\n```css\nhtml {\n  /* Depending on the user settings, this can be 9px, 12px, 16px, 20px, 24px */\n  font-size: 100%;\n}\n```\n\nSetting the root font size to a percentage value will respect user choices and allow you to scale the other parts of your application accordingly by using [relative length units such as `em` or `rem`](https://developer.mozilla.org/en-US/docs/Learn/CSS/Building_blocks/Values_and_units#relative_length_units). A trick used to facilitate rem calculations is to set the root font size to 62.5%, which defaults to `10px` on default settings:\n\n```css\nhtml {\n  /* 1rem = 10px */\n  font-size: 62.5%;\n}\n\n.container {\n  /* When very small font-size is set : 70rem = ~395px */\n  /* When small font-size is set      : 70rem = ~525px */\n  /* When normal font-size is set     : 70rem = ~700px */\n  /* When large font-size is set      : 70rem = ~875px */\n  /* When very large font-size is set : 70rem = ~1050px */\n  max-width: 70rem;\n}\n```\n\n…with that, you should be able to size everything using relative length units without a headache. Keep in mind that you don’t have to limit yourself to font sizes. You can use `rem` unit on breakpoints, widths, heights, and any other CSS property.\n\n<Newsletter />\n\n## Use a color scheme based on the user’s preferred theme\n\n[The `prefers-color-scheme` media query](https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-color-scheme) can be used to make your website adapt to the user’s preferred color scheme. The user might indicate this preference by changing the color scheme in their operating system.\n\n```css\n@media (prefers-color-scheme: dark) {\n  :root {\n    --text-primary: #fff;\n    --background: #000;\n  }\n}\n\n@media (prefers-color-scheme: light) {\n  :root {\n    --text-primary: #000;\n    --background: #fff;\n  }\n}\n```\n\nLight and dark modes have different use cases but both contribute to the [health & well-being](https://www.health.harvard.edu/staying-healthy/blue-light-has-a-dark-side) of the audience. A light mode will be preferred in a well-lit room or direct sunlight, whereas dark mode is preferred during the night or when saving the battery life.\n\n## Adapt to the user’s preferred contrast level\n\n[The `prefers-contrast` media query](https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-contrast) can be used to make your website adapt to the user’s preferred contrast level. The user might indicate this preference by changing the contrast level in their operating system.\n\n```css\n/* When users have no contrast preferences */\n.element {\n  outline: 2px dashed black;\n}\n\n/* When users prefer a higher level of contrast */\n@media (prefers-contrast: more) {\n  .element {\n    outline: 2px solid black;\n  }\n}\n\n/* When users prefer a lower level of contrast */\n@media (prefers-contrast: less) {\n  .element {\n    outline: 2px dashed gray;\n  }\n}\n```\n\n## Use a range of colors supported by the user’s device\n\n[The `color-gamut` media query](https://developer.mozilla.org/en-US/docs/Web/CSS/@media/color-gamut) can be used to detect the approximate range of colors that are supported by the user monitor. You can use it to adapt your color palette adaptively to the user’s display.\n\n```css\n/* Assume the output device can support approximately the sRGB gamut or more */\n:root {\n  --primary: …;\n}\n\n/* The device supports the p3 gamut: larger than and includes the sRGB gamut */\n@media (color-gamut: p3) {\n  :root {\n    --primary: …;\n  }\n}\n\n/* The device supports rec2020 gamut: larger than and includes the p3 gamut */\n@media (color-gamut: rec2020) {\n  :root {\n    --primary: …;\n  }\n}\n```\n\nIf you want to make full use of larger gamuts, you need to use new CSS colors formats ([`lab`](https://developer.mozilla.org/en-US/docs/Web/CSS/color_value/lab), [`lch`](https://developer.mozilla.org/en-US/docs/Web/CSS/color_value/lch), [`display-p3`](https://developer.mozilla.org/en-US/docs/Web/CSS/color_value/color)) or [fall back to images, as they support color profiles](https://twitter.com/panic/status/1106633444157607936). Keep in mind that ultra-bright colors available on the `p3` and `rec2020` gamuts can be uncomfortable and damage the screen if used on static content.\n\n{\n  /**\n   * *[gamut]: the range of colors that can be displayed\n   * *[gamuts]: the range of colors that can be displayed\n   */\n}\n","excerpt":"Most of the designs are rarely built with user preferences in mind, it is the appearance that matters after all! Few people realize the way you respect…","tableOfContents":{"items":[{"url":"#prevent-animations-if-a-user-prefers-reduced-motion","title":"Prevent animations if a user prefers reduced motion"},{"url":"#size-content-based-on-the-users-preferred-font-size","title":"Size content based on the user’s preferred font size"},{"url":"#use-a-color-scheme-based-on-the-users-preferred-theme","title":"Use a color scheme based on the user’s preferred theme"},{"url":"#adapt-to-the-users-preferred-contrast-level","title":"Adapt to the user’s preferred contrast level"},{"url":"#use-a-range-of-colors-supported-by-the-users-device","title":"Use a range of colors supported by the user’s device"}]},"fields":{"slug":"/blog/2021-12-13-accessible-css-that-respects-user-choices/","timeToRead":{"minutes":4.625,"words":925}},"frontmatter":{"title":"Accessible CSS that respects the users’ choices","authors":["Bartosz Łaniewski"],"keywords":["CSS","Accessibility"],"language":"en","description":null,"dateCreated":"December 12, 2021","dateCreatedMeta":"2021-12-13 00:00:00 +0100","dateUpdated":"December 25, 2023","dateUpdatedMeta":"2023-12-26 00:00:00 +0100","datePublished":"December 12, 2021","datePublishedMeta":"2021-12-13 00:00:00 +0100"},"internal":{"contentFilePath":"/home/runner/work/bartozzz.github.io/bartozzz.github.io/content/blog/2021-12-13-accessible-css-that-respects-user-choices/index.md"}},{"id":"dd3c3697-6f84-5214-b627-3e35cce88fd5","body":"\nLazy loading is a well-known technique for improving performance and reducing the associated resource costs. It’s so effective that it’s even [being added to the web standard](https://github.com/whatwg/html/pull/3752) via the `loading=\"lazy\"` attribute. In this article, we will learn how to perform lazy resource loading and code splitting in React.\n\n> **Note:** at the time of writing this article, a lot of APIs are still in development and are not ready to be used in production.\n\n## Glossary\n\n> **Code splitting** […] allows you to split your code into various bundles which can then be loaded on demand or in parallel. It can be used to achieve smaller bundles and control resource load prioritization which, if used correctly, can have a major impact on load time. ~ [Webpack](https://webpack.js.org/guides/code-splitting/)\n\n> **Lazy loading** is a design pattern […] used to defer initialization of an object until the point at which it is needed. It can contribute to efficiency in the program’s operation if properly and appropriately used. […] The performance gains are especially significant if the initialization of the object is costly, such as in case of accessing network services. ~ [Wikipedia](https://en.wikipedia.org/wiki/Lazy_loading)\n\n## Problem\n\nA lot of <abbr title=\"Single-Page Application: a web application that loads once and dynamically updates as the response for user interactions.\">SPAs</abbr> nowadays are \"monolithic\" – there’s a giant JavaScript bundle that contains all of the application’s files. This bundle is required via a `<script>` tag, gets downloaded on the initial visit, and is hopefully cached. This results in:\n\n- a **longer initial load**: we download all of the app’s code, even if it’s not needed to perform the initial render or not used at all;\n- **faster application rendering and in-app navigation**: all of the components are already downloaded and don’t need to be lazily fetched.\n\nThis is the typical drawback of code-splitting: the initial page load is faster but each dynamic import degrades the visible in-app performance.\n\nDevelopers tend to provide visual feedback for each asynchronous action. It often results in an immense amount of loaders and it’s still badly perceived by users. Once the lazy components render, they can perform other asynchronous actions (like network requests) which adds another layer of loaders.\n\nAs a developer, you need to find the perfect balance between initial and dynamic loading and focus on creating great fallback experiences.\n\n<Newsletter />\n\n## Solutions\n\nConcurrent React can partially render a tree without committing the result.\n\n### Code splitting\n\nReact 16.6 introduced [`React.lazy`](https://react.dev/reference/react/lazy) which allows us to perform code splitting and a [`Suspense`](https://react.dev/reference/react/Suspense) component which renders placeholders for lazy-loaded resources.\n\n```jsx\nimport React, { Suspense, lazy } from \"react\";\n\nconst Foo = lazy(() => import(\"./Foo\"));\nconst Bar = lazy(() => import(\"./Bar\"));\n\nconst LazyFooBar = () => (\n  <ErrorBoundary>\n    <Suspense maxDuration={1500} fallback={\"Loading…\"}>\n      <Foo />\n\n      <Suspense maxDuration={1000} fallback={\"Loading…\"}>\n        <Bar />\n      </Suspense>\n    </Suspense>\n  </ErrorBoundary>\n);\n```\n\nThe dynamic `import()` tells the bundler to exclude requested files from the main bundle. `React.lazy` returns a special component type that will suspend the render until it resolves or rejects The exact behavior is described in the following [RFC](https://github.com/reactjs/rfcs/blob/main/text/0064-lazy.md):\n\n> `React.lazy` accepts a Promise factory, and returns a new component type. When React renders that type for the first time, it triggers the Promise factory […]. If the Promise is fulfilled, React reads the `.default` value from it […], and uses it as a component type for rendering. If the Promise is rejected, the rejection is handled in the same way as React normally handles errors (by letting the nearest error boundary handle it). After the code has loaded, React caches the Promise result. Next renders of the components with this type become synchronous and have no extra cost.\n\n`Suspense` allows you to define a fallback placeholder which is displayed when the render is in the suspended state. It also allows you to configure the delay after which the fallback should be shown (via the `maxDuration` property). It will prevent the fallback component from showing up on fast networks.\n\n`Suspense` is quite similar to `ErrorBoundary`. In fact, you can think of `Suspense` as being the `try { … }` block whereas `ErrorBoundary` is the `catch (error) { … }` block.\n\n### Lazy loading and preloading\n\nReact team is working on an experimental library named [`react-cache`](https://github.com/facebook/react/tree/master/packages/react-cache). It provides APIs for implementing various caches for React applications. As it is dependent on some not-yet-released React APIs, this library should not be used in production.\n\n#### API calls\n\nOne of `react-cache` use cases is to suspend rendering on pending requests.\n\n```javascript\nconst FooListResource = unstable_createResource((query) => fetchFooList(query));\n```\n\nIn our render, we just read the data using the `FooListResource.read`. This method returns the response from the `unstable_createResource` Promise factory and tells the nearest parent `React.Suspense` to stop the rendering and display the fallback till the resource is ready. The implementation is simple:\n\n```jsx\nconst FooList = () => {\n  const response = FooListResource.read({\n    search: \"search string\",\n  });\n\n  return (\n    <ul>\n      {response.map((item) => (\n        <li key={item.id}>{item.text}</li>\n      ))}\n    </ul>\n  );\n};\n```\n\n#### Embedded documents\n\nYou can use `react-cache` to lazy load embedded documents, such as images, videos, scripts, stylesheets, and more. The implementation is quite similar to caching API calls. We start with creating an image resource:\n\n```javascript\nconst ImageResource = unstable_createResource(\n  (src) =>\n    new Promise((resolve, reject) => {\n      const img = new Image();\n      img.src = src;\n      img.onload = resolve;\n      // img.onerror = reject;\n    })\n);\n```\n\nNow, we need to create an alternative `img` component which will make use of the `ImageResource`. For this, we simply need to call `ImageResource.read(src)` – it will tell the nearest parent `React.Suspense` to stop the rendering and display the fallback till the image is fully loaded. The implementation is straightforward:\n\n```jsx\nconst Img = ({ src, ...props }) => {\n  ImageResource.read(src);\n\n  return <img src={src} {...props} />;\n};\n```\n\nNow, we can create a wrapper that will take care of providing the low-resolution fallback image for us – we just need to wrap the newly created `Img` component with a `React.Suspense` and provide a fallback image, as follows:\n\n```jsx\nconst LazyImg = ({ lowResSrc, highResSrc, ...props }) => (\n  <React.Suspense fallback={<img {...props} src={lowResSrc} />}>\n    <Img {...props} src={highResSrc} />\n  </React.Suspense>\n)\n```\n\nThere’s a GitHub project named `the-platform` which turns Web APIs into React Hooks and Suspense-friendly React components. It provides a set of lazy components out of the box, such as:\n\n- [`<Img>`](https://github.com/jaredpalmer/the-platform#img)\n- [`<Script>`](https://github.com/jaredpalmer/the-platform#script)\n- [`<Video>`](https://github.com/jaredpalmer/the-platform#video)\n- [`<Audio>`](https://github.com/jaredpalmer/the-platform#audio)\n- [`<Preload>`](https://github.com/jaredpalmer/the-platform#preload)\n- [`<Stylesheet>`](https://github.com/jaredpalmer/the-platform#stylesheet)\n\n## Resources\n\n1. https://legacy.reactjs.org/docs/code-splitting.html\n2. https://medium.com/@rossbulat/react-lazy-suspense-and-concorrent-react-breakdown-with-examples-2758de98cb1c\n3. https://github.com/palmerhq/the-platform\n4. https://youtube.com/watch?v=SCQgE4mTnjU\n5. https://www.youtube.com/watch?v=ByBPyMBTzM0\n","excerpt":"Lazy loading is a well-known technique for improving performance and reducing the associated resource costs. It’s so effective that it’s even being added…","tableOfContents":{"items":[{"url":"#glossary","title":"Glossary"},{"url":"#problem","title":"Problem"},{"url":"#solutions","title":"Solutions","items":[{"url":"#code-splitting","title":"Code splitting"},{"url":"#lazy-loading-and-preloading","title":"Lazy loading and preloading"}]},{"url":"#resources","title":"Resources"}]},"fields":{"slug":"/blog/2019-04-19-lazy-loading-and-code-splitting-in-react-apps/","timeToRead":{"minutes":5.375,"words":1075}},"frontmatter":{"title":"Lazy loading and code splitting in React","authors":["Bartosz Łaniewski"],"keywords":["React"],"language":"en","description":null,"dateCreated":"April 19, 2019","dateCreatedMeta":"2019-04-20 00:00:00 +0100","dateUpdated":"December 25, 2023","dateUpdatedMeta":"2023-12-26 00:00:00 +0100","datePublished":"April 19, 2019","datePublishedMeta":"2019-04-20 00:00:00 +0100"},"internal":{"contentFilePath":"/home/runner/work/bartozzz.github.io/bartozzz.github.io/content/blog/2019-04-19-lazy-loading-and-code-splitting-in-react-apps/index.md"}},{"id":"fc31b533-dfb5-52e8-88da-d3689bc52256","body":"\nMaintaining large React projects can be a difficult task. Below are a few practices I’ve adapted over the years working with React projects of all scales. A low of those practices were directly taken or inspired by excellent resources found in the React/Redux community, precisely:\n\n- [React: official documentation](https://react.dev/);\n- [Redux: official documentation](https://redux.js.org/);\n- [Ducks: Redux Reducer Bundles](https://github.com/erikras/ducks-modular-redux);\n- [Re-ducks: Building on the duck legacy](https://github.com/alexnm/re-ducks);\n- [React & Redux TypeScript guide](https://github.com/piotrwitek/react-redux-typescript-guide);\n\n**The proposed architecture is not meant to be enforced dogmatically and is a work in progress that might change over time.**\n\n## File structure\n\nDan Abramov created a [guide](https://react-file-structure.surge.sh/) for organizing files and he made a very good point. For months I’ve been following the “good” ways to organize React projects: starting at the separation of concerns with Presentational and Container components and finishing with adapting [ducks](https://github.com/erikras/ducks-modular-redux).\n\nIt worked well for small projects, but as they grew to be 30 different, unique screens and over 200 components, it became more difficult to maintain all of this together. At Milo, we came up with a directory structure that is inspired by Django and best practices from React, taking the separation of concerns to its extreme.\n\n```\nsrc/\n├── App.tsx\n├── index.ts\n├── store.ts\n├── types.ts\n├── shared/\n│    └── ComponentName.tsx\n├── modules/\n│    └── <moduleName>/\n│          ├── components/\n│          │     └── ComponentName.tsx\n│          ├── actionCreators.ts\n│          ├── actionTypes.ts\n│          ├── apiCalls.ts\n│          ├── operations.ts\n│          ├── selectors.ts\n│          ├── reducers.ts\n│          ├── utils.ts\n│          ├── types.ts\n│          └── index.ts\n└── screens/\n      ├── <screenNamespace>/\n      │     ├── SubcreenNameA.tsx\n      │     └── SubcreenNameB.tsx\n      └── Navigation.ts\n```\n\n### Shared\n\nThis contains the shared code used all across your app. It can include configuration files, primary presentational components (i.e. Buttons, Inputs, Grid, …) helpers to work with the API, and pretty much everything that doesn’t fit in other parts of the proposed architecture.\n\n### Screens\n\nScreens are components that are directly mounted on routes ([`react-router`](https://github.com/remix-run/react-router), [`react-navigation`](https://github.com/react-navigation/react-navigation)). They render shared and/or module components.\n\n### Modules\n\nSometimes, we need to share the logic between web (React) and mobile (React Native) apps. The proposed structure makes it very easy to reuse and maintain the code without influencing other app parts.\n\nThe main idea of `modules/` is to group a strongly coupled part of the application and make it as reusable as possible. It contains all the required components (later used in screens) as well as reducers, action creators, and other state-related utilities.\n\n- A module must contain the entire logic for handling its concept;\n- A module may contain all the required components to present its concept.\n\n#### Components\n\nWe don’t always follow the concept of a container and presentational components – the promoted thing with this concept is the separation of concerns which can be achieved in different, more maintainable ways, for example, through the Hooks API. Do what is more suitable for your case.\n\n> “I don’t suggest splitting your components like this anymore. If you find it natural in your codebase, this pattern can be handy. But I’ve seen it enforced without any necessity and with almost dogmatic fervor far too many times. The main reason I found it useful was because it let me separate complex stateful logic from other aspects of the component. Hooks let me do the same thing without an arbitrary division.” – [Dan Abramov](https://medium.com/@dan_abramov/smart-and-dumb-components-7ca2f9a7c7d0)\n\n#### Index\n\nThe `index.ts` file should expose the public API of a module. Everything that is not exposed in this file should be considered private and never accessed from the outside.\n\n- The default export must be the reducer.\n- It must export `actions`, `operations`, `selectors`, and `types`.\n- It must expose all the components.\n\n```typescript\nimport * as actions from \"./actionCreators\";\nimport * as operations from \"./operations\";\nimport * as selectors from \"./selectors\";\nimport * as types from \"./types\";\nimport reducer from \"./reducers\";\n\n// Store/state-related stuff:\nexport default reducer;\nexport { actions, operations, selectors, types };\n\n// Components:\nexport { default as ComponentNameA } from \"./components/ComponentNameA\";\nexport { default as ComponentNameB } from \"./components/ComponentNameB\";\n```\n\n#### Action Types\n\nAction types are constants used by action creators and reducers. Each action type should be unique and prefixed by the project and module name.\n\n```typescript\nexport const POSTS_REQUEST = \"@@<project_name>/<module_name>/POSTS_REQUEST\";\nexport const POSTS_PROCESS = \"@@<project_name>/<module_name>/POSTS_PROCESS\";\n```\n\nYour action types should be pure string literals. Dynamic string operations (like template strings, string concatenation, etc.) will widen literal type to its supertype string. This will break contextual typing in reducer cases when using TypeScript or Flow.\n\n#### Action Creators\n\nThe action creators should follow the [Flow Standard Action](https://github.com/redux-utilities/flux-standard-action) specification when possible. Action shape should be predictable and known by the developers. Action creators should not contain any logic, nor transform the received payload – it makes them harder to test and the code is harder to debug.\n\n```typescript\nimport { createStandardAction } from \"typesafe-actions\";\nimport * as Types from \"./actionTypes\";\nimport { Payload } from \"./types\";\n\nexport const requestPosts =\n  createStandardAction(Types.POSTS_REQUEST)<void>();\n\nexport const processPosts =\n  createStandardAction(Types.POSTS_REQUEST)<Payload | Error>();\n```\n\nYou should not export any default value in `actionCreators.ts`. Using named exports, it is easier to map dispatch to all actions exposed by a module using [`bindActionCreators`](https://redux.js.org/api/bindactioncreators), as follows:\n\n```typescript\nimport { bindActionCreators } from \"redux\";\nimport * as Types from \"../../types\";\nimport { actions as moduleActionsA } from \"../moduleA\";\nimport { actions as moduleActionsB } from \"../moduleB\";\n\nconst mapDispatchToProps = (dispatch: Dispatch<Types.RootAction>) =>\n  bindActionCreators({ ...moduleActionsA, ...moduleActionsB }, dispatch);\n```\n\n<Newsletter />\n\n#### API Calls\n\nAPI endpoints should not be hand-coded – it makes the code prone to errors and harder to maintain as API evolves. I encourage you to create a small configuration file with all available endpoints in `config.ts` file, then reuse those endpoints in `apiCalls.ts`.\n\n##### Configuration\n\n```typescript\nconst URL = \"\";\nconst API = \"\";\n\nexport default {\n  v1: {\n    posts: {\n      get(id: number, meta?: Object) {\n        return `${URL}${API}v1/posts/${id}${createQueryString(meta)}`;\n      },\n      list(meta?: Object) {\n        return `${URL}${API}v1/posts${createQueryString(meta)}`;\n      }\n    }\n  },\n\n  v2: { /* ... */ }\n};\n```\n\n##### API Calls\n\n```typescript\nexport const fetchPost = (id: number, meta: Object) =>\n  fetch(urls.v1.posts.get(id, meta))\n    .then(response => response.json());\n\nexport const fetchPosts = (meta: Object) =>\n  fetch(urls.v1.posts.list(meta))\n    .then(response => response.json());\n```\n\n#### Operations\n\nOperations can be [thunks](https://github.com/reduxjs/redux-thunk) or [sagas](https://redux-saga.js.org/) and everything else that delays the action dispatch. An operation is a function that can contain logic, dispatch multiple actions based on some predicates, and manipulate their payload.\n\n```typescript\nimport * as Types from \"../types\";\nimport * as actions from \"./actionCreators\";\nimport * as API from \"./apiCalls\";\n\nexport const doFooStuff = (payload: Object) =>\n  (dispatch: Dispatch<Types.RootAction>) => {\n    dispatch(actions.requestPosts());\n\n    API.fetchPosts(payload.meta)\n      .then(data => dispatch(actions.processPosts(normalizePosts(data))))\n      .catch(err => dispatch(actions.processPosts(err, true)));\n  };\n```\n\n#### Selectors\n\nSelectors can compute derived data, allowing Redux to store the minimal possible state. A selector is not recomputed unless one of its arguments changes. It minimized the amount of component re-renders to the minimum. Have a look at the excellent [reselect](https://github.com/reduxjs/reselect) package.\n\nConsider the following example – it renders a list of posts created by the currently logged-in user:\n\n```typescript\nclass PostsList extends React.PureComponent {\n  render() {\n    return (\n      <ul>\n        {\n          this.props.posts\n            .filter(post => post.author = this.props.userId)\n            .map(post => (\n              <div>\n                <p>{post.title}</p>\n                <p>{post.content}</p>\n              </div>\n            ))\n        }\n      </ul>\n    );\n  }\n}\n\nconst mapStateToProps = state => ({\n  posts: state.posts.data,\n  userId: state.auth.user.id\n});\n```\n\nIn the example above, a render is triggered every time the post collection changes, even if the changed post is not created by the user. Using selectors, we can avoid those unnecessary re-renders and update the component only if one of the user’s posts has been created or modified:\n\n```typescript\n// selectors.ts\nimport { createSelector } from \"reselect\";\n\nconst postsSelector = state => state.posts.data;\nconst userSelector = state => state.auth.user;\nconst userPostsSelector = createSelector(\n  postsSelector,\n  userSelector,\n  (posts, user) => posts.filter(post => post.author === user.id)\n);\n```\n\n```typescript\n// PostsList.tsx\nclass PostsList extends React.PureComponent {\n  render() {\n    return (\n      <ul>\n        {this.props.userPosts.map(post => (\n          <div>\n            <p>{post.title}</p>\n            <p>{post.content}</p>\n          </div>\n        ))}\n      </ul>\n    );\n  }\n}\n\nconst mapStateToProps = state => ({\n  userPosts: userPostsSelector(state)\n});\n```\n\nThe other thing about selectors is that they facilitate the work with a part of the application that was developed by somebody else – you don’t need to know the state’s shape to work with it if the exposed selectors are enough and well-documented.\n\n#### Reducers\n\nYou should export one reducer per module, but a module can be composed of multiple reducers. Don’t be afraid to break your reducer into multiple chunks to reduce complexity and make it easier to test. You can always combine them using [`combineReducers`](https://redux.js.org/api/combinereducers).\n\n```typescript\nimport { combineReducers } from \"redux\";\nimport { Action, PostsState, ErrorsState, LoadingState } from \"./types\";\nimport * as Types from \"./actionTypes\";\n\nexport const postsReducer = (state: PostsState = {}, action: Action) => {\n  switch (action.type) {\n    case Types.POSTS_PROCESS:\n      if (!action.error) return {...state, action.payload};\n\n    default:\n      return state;\n  }\n}\n\nexport const errorsReducer = (state: ErrorsState = null, action: Action) => {\n  switch (action.type) {\n    case Types.POSTS_PROCESS:\n      if (action.error) return action.payload;\n\n    default:\n      return state;\n  }\n}\n\nexport const loadingReducer = (state: LoadingState = false, action: Action) => {\n  switch (action.type) {\n    case Types.POSTS_REQUEST:\n      return true;\n    case Types.POSTS_PROCESS:\n      return false;\n    default:\n      return state;\n  }\n}\n\nexport default combineReducers({\n  data: postsReducer,\n  errors: errorsReducer,\n  loading: loadingReducer,\n});\n```\n\n#### Types\n\nIf you use Flow or TypeScript, it’s a good idea to keep all the types in one place (`types.ts`). By doing so, we can expose all of them at once to other modules of the app. This is particularly handy when we need to expose the root `Action` and `State` which is used in every selector and container. Here’s an example of `/types.ts`:\n\n```typescript\nimport { AnyAction } from \"redux\";\nimport { StateType } from \"typesafe-actions\";\nimport rootReducer from \"./reducers\";\nimport { types as FooTypes } from \"../../modules/foo\";\nimport { types as BarTypes } from \"../../modules/bar\";\n\nexport type RootState =\n  StateType<typeof rootReducer>;\n\nexport type RootAction =\n  FooTypes.Action | BarTypes.Action | AnyAction;\n```\n\n### Utilities for state management\n\nYou can think of Redux as a low-level API – it doesn’t force any particular patterns and allows you pretty much to do whatever you want.\n\n- [Ramda](https://ramdajs.com/): a practical functional library for JavaScript programmers.\n- [Immer](https://github.com/immerjs/immer): create the next immutable state by mutating the current one.\n\n### Utilities for creating styles\n\nCreating styles can be a pain, especially in React Native or when you need to create custom styles based on the state. [Styled Components](https://styled-components.com/ecosystem) can come in handy – they allow you to create styles directly in JavaScript using SCSS syntax.\n\n### Tips and tricks\n\n#### You can use reducers on the inner state\n\nCreating reducers to handle the inner component state is a good practice in the case when you have complex state logic – it is easier to test and in most cases, less error-prone. Creating reducers for inner state management is even easier with the new Hooks API.\n\n**Example:** from official React [`useReducer` example](https://react.dev/reference/react/useReducer):\n\n```jsx\nexport const initialState = { count: 0 };\n\nexport function reducer(state, action) {\n  switch (action.type) {\n    case \"increment\": return {count: state.count + 1};\n    case \"decrement\": return {count: state.count - 1};\n    default: throw new Error();\n  }\n}\n\nexport default function Counter({initialState}) {\n  const [state, dispatch] = useReducer(reducer, initialState);\n\n  return (\n    <>\n      Count: {state.count}\n      <button onClick={() => dispatch({type: \"increment\"})}>+</button>\n      <button onClick={() => dispatch({type: \"decrement\"})}>-</button>\n    </>\n  );\n}\n```\n\n### Do’s and don’ts\n\n#### Never render a list of children without assigning a unique key to each\n\nThis can have a huge impact on the performance, even bigger if you render a big list of elements. As from React documentation:\n\n> Keys help React identify which items have changed, are added, or are removed. Keys should be given to the elements inside the array to give the elements a stable identity. The best way to pick a key is to use a string that uniquely identifies a list item among its siblings. Most often you would use IDs from your data as keys.\n\n**Don’t:**\n\n```jsx\nclass FooComponent extends React.Component {\n  render() {\n    return this.props.data.map(item => <Item data={item} />);\n  }\n}\n\nclass FooComponent extends React.Component {\n  render() {\n    return this.props.data.map((item, index) => <Item key={index} data={item} />);\n  }\n}\n```\n\n**Do:**\n\n```jsx\nclass FooComponent extends React.Component {\n  render() {\n    return this.props.data.map(item => <Item key={item.id} data={item} />);\n  }\n}\n```\n\n#### Never create functions or objects in props\n\nThis can have a huge impact on the performance. If you create new objects or functions in the props, a new reference will be passed down to the child each time its parents re-render, resulting in unnecessary re-renders and probably more unwanted behaviors.\n\n**Don’t:**\n\n```jsx\nclass FooComponent extends React.Component {\n  render() {\n    return (\n      <FooChild\n        onClick={() => this.props.handleClick(...args)}\n        data={this.props.filter(item => item.id === 5)}\n      />\n    );\n  }\n}\n```\n\n**Do:**\n\n```jsx\nclass FooComponent extends React.Component {\n  onClick = (...args) => event => {\n    return this.props.handleClick(...args);\n  };\n\n  render() {\n    return (\n      <FooChild\n        onClick={this.onClick(...args)}\n        data={this.props.filteredData}\n      />\n    );\n  }\n}\n```\n\n#### Avoid duplicating data between props and state\n\nIf some data can be derived or calculated directly from the props, it’s unnecessary to replicate this data in the state. Props should be the only source of truth. In fact – if you want to calculate the state based on the received props, you’ll need to create a `componentDidUpdate` method and keep your state and props in sync – this is an anti-pattern.\n\nThe only case when assigning props to a state is acceptable is to pass initial data to a component that doesn’t need to be in sync with the store, e.g. forms.\n\n**Avoid:**\n\n```jsx\nclass FooComponent extends React.Component {\n  state = {\n    foo: this.props.foo,\n    bar: this.props.bar,\n  }\n}\n```\n\n#### Avoid overusing HOCs\n\nAs Michael Jackson (React-Router co-creator) said:\n\n> “Next time you think you need a HOC (higher-order component) in, you probably don’t. I can do anything you’re doing with your HOC using a regular component with a [render prop](https://legacy.reactjs.org/docs/render-props.html).“ – [Michael Jackson](https://twitter.com/mjackson/status/885910553432018945)\n\n#### Avoid using Components without `shouldComponentUpdate`\n\nA [`React.Component`](https://react.dev/reference/react/Component), when used without `shouldComponentUpdate`, will re-render on every prop and state change.\n\n1. Consider creating a `shouldComponentUpdate() `method to prevent unnecessary re-renders.\n2. Consider using the built-in `PureComponent` instead of writing `shouldComponentUpdate` by hand. `PureComponent` performs a shallow comparison of props and state, and reduces the chance that you’ll skip a necessary update.\n","excerpt":"Maintaining large React projects can be a difficult task. Below are a few practices I’ve adapted over the years working with React projects of all scales.…","tableOfContents":{"items":[{"url":"#file-structure","title":"File structure","items":[{"url":"#shared","title":"Shared"},{"url":"#screens","title":"Screens"},{"url":"#modules","title":"Modules"},{"url":"#utilities-for-state-management","title":"Utilities for state management"},{"url":"#utilities-for-creating-styles","title":"Utilities for creating styles"},{"url":"#tips-and-tricks","title":"Tips and tricks"},{"url":"#dos-and-donts","title":"Do’s and don’ts"}]}]},"fields":{"slug":"/blog/2019-03-01-enterprise-scale-react-redux-project-architecture/","timeToRead":{"minutes":11.785,"words":2357}},"frontmatter":{"title":"Enterprise-scale React & Redux project architecture","authors":["Bartosz Łaniewski"],"keywords":["React","Architecture"],"language":"en","description":null,"dateCreated":"February 28, 2019","dateCreatedMeta":"2019-03-01 00:00:00 +0100","dateUpdated":"December 25, 2023","dateUpdatedMeta":"2023-12-26 00:00:00 +0100","datePublished":"February 28, 2019","datePublishedMeta":"2019-03-01 00:00:00 +0100"},"internal":{"contentFilePath":"/home/runner/work/bartozzz.github.io/bartozzz.github.io/content/blog/2019-03-01-enterprise-scale-react-redux-project-architecture/index.md"}},{"id":"e50ca655-c772-51eb-ab28-0060ebef3294","body":"\nWith JavaScript increasingly gaining popularity, Progressive Web Apps (_PWAs_) might replace native mobile & desktop apps in the future. In this post, we will learn how to develop and test offline-first, Vue-based Progressive Web Applications and why it is worth it.\n\n## Introduction to Progressive Web Apps (PWAs)\n\nProgressive Web Apps can be installed on most devices like native apps. They are meant to be **reliable** (work on each platform, even offline), **fast**, and provide a **native-like** user experience. These apps combine the best of web and native solutions:\n\n- They are **rapid to develop**, **cross-platform** and **responsive** by nature. JavaScript provides a lot of frameworks (such as [Vue](https://vuejs.org/), [React](https://react.dev/)) and dedicated front-end component libraries to boost productivity (Bootstrap, Material UI). You write your code once and deploy your application on every platform;\n- **Fast load**, **fast response**. Progressive web apps are comparable to native solutions in terms of efficiency. With _service workers_, cache, and several optimizations made in engines running JavaScript, Progressive Web Applications’ loading and response times are very low.\n\nIt is important to notice that if you are planning on making your application a PWA, you don’t have to rewrite all the logic. For example, your application should work offline, but it doesn’t mean that you must set up a background queue or store your data in a persistent storage – an offline message (e.g. “_You’re offline, check your network status._”) is enough.\n\n### Browser support\n\nProgressive Web Apps are compatible with every mobile device that supports one of the following browsers:\n\n- **Google Chrome** (since v40+);\n- **Firefox** (since v44+);\n- **Safari** (since v11.1+);\n- **Edge** (since v17+);\n\nAdditionally, Google Chrome recently added support for Progressive Web Apps on desktop platforms, such as:\n\n- **Chrome OS** (since Chrome 67+);\n- **Linux** (since Chrome 70+);\n- **Windows** (since Chrome 70+);\n- **macOS** (since Chrome 72+);\n\n## Getting started\n\nIn this article, we will be using [Vue-CLI](https://cli.vuejs.org/) to create a brand-new Vue project. You can follow the instructions on [their website](https://cli.vuejs.org/guide/creating-a-project.html#vue-create). I encourage you to manually select the following features:\n\n1. **Babel** (used in this tutorial);\n2. **TypeScript** (used in this tutorial);\n3. **Progressive Web App** (PWA) support (required in this tutorial);\n\n### Setting up a service worker\n\n[Service workers](https://developer.mozilla.org/en-US/docs/Web/API/Service_Worker_API) (not to be confused with [_Worklets_](https://developer.mozilla.org/en-US/docs/Web/API/Worklet) or raw [_Workers_](https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers)) represents a proxy between the browser and the network – they allow you to intercept requests made by your application and handle each one separately enabling offline access, browser-level caching and more.\n\nLike Workers, service workers are executed on a different thread and communicate with the main one – your web application, via an API: since Workers are on a different thread, they don’t have direct access to any of your web app internals. Workers generally offer more functionality than the standard browser API and Service Workers, i.e. to send push notifications, create periodic background tasks, hook into OS internals ([Share Target API](https://developers.google.com/web/updates/2016/09/navigator-share), …).\n\nTo use Workers, your website must be served over HTTPS. Even if service Workers are not compatible with some web browsers, you can safely add them to your application – it will not break the experience for any user (_progressive enhancement_).\n\n[`@vue/cli-plugin-pwa`](https://github.com/vuejs/vue-cli/tree/dev/packages/@vue/cli-plugin-pwa) should take care of creating a Service Worker. The generated Service Worker will cache all built resources. If you want to create a service worker manually, you can modify this behavior in the `vue.config.js` file by adding the following lines:\n\n```typescript\nmodule.exports = {\n pwa: {\n   workboxPluginMode: \"InjectManifest\",\n   workboxOptions: {\n     swSrc: \"public/service-worker.js\"\n   }\n }\n};\n```\n\nThe path in `swSrc` option must match the path specified in the `registerServiceWorker.ts` file, otherwise, your Service Worker will not be registered. You can then use [Workbox](https://developers.google.com/web/tools/workbox/guides/get-started) to define custom rules for request interceptors. Here’s an example:\n\n```javascript\n// public/service-worker.js\nworkbox.setConfig({ debug: true });\nworkbox.precaching.precacheAndRoute([]);\n\n// Cache images:\nworkbox.routing.registerRoute(\n /\\.(?:png|gif|jpg|jpeg|svg)$/,\n workbox.strategies.staleWhileRevalidate({\n   cacheName: \"images\",\n   plugins: [\n     new workbox.expiration.Plugin({\n       maxEntries: 60,\n       maxAgeSeconds: 30 * 24 * 60 * 60 // 30 days\n     })\n   ]\n })\n);\n\n// Cache Google fonts:\nworkbox.routing.registerRoute(\n new RegExp(\"https://fonts.(?:googleapis|gstatic).com/(.*)\"),\n workbox.strategies.cacheFirst({\n   cacheName: \"googleapis\",\n   plugins: [\n     new workbox.expiration.Plugin({\n       maxEntries: 30,\n       maxAgeSeconds: 30 * 24 * 60 * 60 // 30 days\n     })\n   ]\n })\n);\n```\n\n### Prompting the user to install\n\nInstalling a Progressive Web Application works the same way on both mobile and desktop devices. The website must meet a few requirements before it can be prompted to install:\n\n1. Meet a user engagement heuristic;\n2. Include a web app manifest file;\n3. Have an icon to represent the app on the device;\n4. Have a registered service worker to make the app work offline;\n5. The web app must be served over HTTPS and not already installed;\n\nIf those criteria are met, the web browser will emit a `beforeinstallprompt` event which you can use to notify the user that your app can be installed. The most common way is by adding a button on the website. It is considered best practice to not show a full-page banner or distracting notifications. Let’s add some markup for our `InstallBanner` component:\n\n```html\n<template>\n <div class=\"banner\" v-if=\"deferredPrompt\">\n   <p>Do you want to install Foo App?</p>\n   <button @onClick=\"promptInstall\">Opt for!</button>\n </div>\n</template>\n```\n\nInstead of dealing with adding and removing event listeners for the `beforeinstallprompt` event manually, we can use the [`vue-pwa-install`](https://github.com/Bartozzz/vue-pwa-install) plugin which I wrote for this article. It will emit a `canInstall` in the root event bus – what you need to do is listen for this particular event in one of your components. First, let’s install the `vue-pwa-install` plugin with the following command:\n\n```bash\n$ npm install --save vue-pwa-install\n```\n\nThen, register this installed plugin in your app entry point:\n\n```typescript\nimport Vue from \"vue\";\nimport VueInstall from \"vue-pwa-install\";\n\nVue.use(VueInstall);\n```\n\nOnce registered, we can listen for the `canInstall` event in any component and handle the event to show the install prompt. Let’s add the following code in our `InstallBanner` component:\n\n```html\n<script lang=\"ts\">\n import { Component, Vue } from \"vue-property-decorator\";\n import { BeforeInstallPromptEvent } from \"vue-pwa-install\";\n\n @Component({})\n export default class InstallBanner extends Vue {\n   deferredPrompt: BeforeInstallPromptEvent | void;\n\n   promptInstall() {\n     // Show the prompt:\n     this.deferredPrompt.prompt();\n\n     // Wait for the user to respond to the prompt:\n     this.deferredPrompt.userChoice.then(choiceResult => {\n       if (choiceResult.outcome === \"accepted\") {\n         // User accepted the install prompt\n       }\n\n       this.deferredPrompt = null;\n     });\n   }\n\n   created() {\n     this.$on(\"canInstall\", (event: BeforeInstallPromptEvent) => {\n       // Prevent Chrome >=67 from automatically showing the prompt:\n       event.preventDefault();\n\n       // Stash the event so it can be triggered later:\n       this.deferredPrompt = event;\n     });\n   }\n }\n</script>\n```\n\nAnd that’s all. The banner should be displayed on the website once the 5 requirements listed above are met, and when the user clicks on _Opt for_ button, he will be asked by the browser if he wants to install the app on his local machine.\n\n<Newsletter />\n\n### Prompting the user to update\n\nIn the `registerServiceWorker.ts` file, you should have an updated handler. This function will be executed each time a new version of your website is available – to get the updated version, the user should simply reload the page. It is considered very bad practice to force a page reload, therefore it is advised to create a small banner that will pop up and inform the user about the update. We can start by creating a banner markup in our `index.html` file, as follows:\n\n```html\n<div id=\"update-banner\" class=\"banner\" style=\"display: none\">\n  <p>There’s a new version of Foo App.</p>\n  <button id=\"update-button\">Reload</button>\n</div>\n```\n\nNext, we need to show this banner when a new update comes in and add necessary event handlers for the \"Reload\" button. This can be achieved directly in the `updated` function:\n\n```typescript\nupdated() {\n // New content is available\n const updateBanner = <HTMLElement>document.getElementById(\"update-banner\");\n const updateButton = <HTMLElement>document.getElementById(\"update-button\");\n\n updateBanner.style.display = \"block\";\n updateButton.addEventListener(\"click\", () => {\n   location.reload();\n });\n}\n```\n\nNote that you could create a Vue component instead of a pure HTML-based banner, but then you should store the `updateAvailable` state in your App’ store (e.g. Vuex) and it will require some more work.\n\nIf possible, configure your production environment to serve `service-worker.js` with HTTP caching disabled. Otherwise, if you visit your web app, and then revisit before `service-worker.js` has expired from the cache, you’ll continue to get the update banner showing.\n\n### Handling offline-first forms\n\nThere are 2 ways of handling offline forms: the first one is by intercepting the request when the user is offline and sending it again when there’s an internet connection. There are a few problems that you must take care of:\n\n1. **Concurrency:** what if the data on the remote database has changed when the user was offline? Overwriting it might be an unwanted behavior.\n2. **False positives:** if the user is connected to the internet, it doesn’t necessarily mean that he can send requests yet (i.e. paid hotspots).\n3. **Error handling:** when the request fails, how should we inform the user that the request he tried to make 3 days ago failed?\n4. **Application architecture:** this kind of offline-first form handling often requires a more complex architecture.\n\nThe easier approach is to save the form state in local storage and inform the user that he will be able to submit the form once he is online again. This solution can be implemented in a few lines for each already existing form.\n\nLet’s start with creating a local store in `store/local.ts`. We will use [`LocalForage`](https://github.com/localForage/localForage) library which wraps IndexedDB, WebSQL, or localStorage using a simple but powerful API. It will allow us to store data in the most suitable local storage available on the user’s device:\n\n```typescript\nimport LocalForage from \"localforage\";\n\n// This must be called before any other calls to localForage are made:\nLocalForage.config({\n  name: \"foo-app\",\n  storeName: \"foo-app-store\",\n  version: 1.0\n});\n\nexport default LocalForage;\nexport const formStore = LocalForage.createInstance({ name: \"form\" });\n```\n\nThen, we can modify any form to use the local `formStore` when needed, as follows:\n\n```html\n<template>\n <form @submit=\"onSubmit\">\n   <input type=\"text\" v-model=\"form.author\" placeholder=\"Your name…\" />\n   <input type=\"text\" v-model=\"form.message\" placeholder=\"Message…\" />\n\n   <button type=\"submit\">Send</button>\n </form>\n</template>\n\n<script lang=\"ts\">\n import { Component, Vue } from \"vue-property-decorator\";\n import { formStore } from \"@/store/local\";\n\n type Nullable<T> = T | null;\n type Optional<T> = T | undefined;\n\n interface FormData {\n   author?: Nullable<string>;\n   message?: Nullable<string>;\n }\n\n @Component({})\n export default class SomeForm extends Vue {\n   form: FormData = {\n     author: null,\n     message: null\n   };\n\n   resetForm() {\n     this.form.author = null;\n     this.form.message = null;\n\n     // Reset local storage:\n     formStore.setItem(\"some-form-author\", null);\n     formStore.setItem(\"some-form-message\", null);\n   }\n\n   storeData(data: FormData) {\n     formStore.setItem<Optional<Nullable<string>>>(\"some-form-author\", data.author);\n     formStore.setItem<Optional<Nullable<string>>>(\"some-form-message\", data.message);\n   }\n\n   sendData(data: FormData) {\n     this.resetForm();\n\n     // Make a request here…\n   }\n\n   onSubmit(event: Event) {\n     event.preventDefault();\n     event.stopPropagation();\n\n     // Normalize & validate form data:\n     const form: FormData = {\n       author: this.form.author,\n       message: this.form.message\n     };\n\n     if (navigator.onLine) {\n       this.sendData(form);\n     } else {\n       this.storeData(form);\n     }\n   }\n\n   created() {\n     formStore.getItem<Nullable<string>>(\"some-form-author\").then(value => {\n       this.form.author = value;\n     });\n\n     formStore.getItem<Nullable<string>>(\"some-form-message\").then(value => {\n       this.form.message = value;\n     });\n   }\n }\n</script>\n```\n\n### Showing offline information\n\nIf your application is not fully offline first (e.g. you don’t save the requests in a queue like in the previous section), it is important to notify the users about their connection status. You can use the `navigator.onLine` property and `ononline`, and `onoffline` events or let the [`vue-offline`](https://github.com/filrak/vue-offline) plugin take care of all of this.\n\n```bash\n$ npm install --save vue-offline\n```\n\nIt will add `isOnline`, and `isOffline` data properties and `online`, and `offline` events via a global mixin. We need to register their plugin in `main.ts`, as follows:\n\n```ts\nimport Vue from \"vue\";\nimport VueOffline from \"vue-offline\";\n\nVue.use(VueOffline, { storage: false });\n```\n\nThen we can safely listen for the online and offline events in our `App.vue`:\n\n```html\n<template>\n <div id=\"app\">\n   <section class=\"offline\" v-if=\"!isOnline\">You are offline.</section>\n\n   <router-view></router-view>\n </div>\n</template>\n\n<script lang=\"ts\">\n import { Component, Vue } from \"vue-property-decorator\";\n\n @Component({})\n export default class App extends Vue {\n   isOnline = navigator.onLine;\n\n   created() {\n     this.$on(\"online\", () => {\n       console.log(\"User is now online\");\n       this.isOnline = true;\n     });\n\n     this.$on(\"offline\", () => {\n       console.log(\"User is now offline\");\n       this.isOnline = false;\n     });\n   }\n }\n</script>\n```\n\n### Making Vuex state persistent\n\nIf you want some parts of your data persistent, available in offline mode, you’ll need a persistent store, which replicates and retrieves the Vuex store to/from local storage. In this article, I’ll focus on a Vuex plugin named [`vuex-persist`](https://github.com/championswimmer/vuex-persist). You can download it with the following command:\n\n```bash\n$ npm install --save vuex-persist\n```\n\nSince we are already using LocalForage, we’ll use it to store the persistent data. Let’s create a wrapper over the `vuex-persist` plugin:\n\n```typescript\n// src/store/plugins/persistent.ts\nimport LocalForage from \"localforage\";\nimport VuexPersistence from \"vuex-persist\";\n\nexport default function createPersistedState(options = {}) {\n  return store => {\n    const VuexForage = new VuexPersistence({\n      ...options,\n\n      storage: LocalForage,\n      asyncStorage: true,\n\n      // Used to trigger the `storageReady` event as soon as the state is loaded\n      // from LocalForage:\n      restoreState: (key, storage) =>\n        new Promise(resolve => {\n          storage.getItem(key).then(data => {\n            resolve(data);\n\n            store._vm.$root.$emit(\"storageReady\");\n          });\n        })\n    });\n\n    return VuexForage.plugin(store);\n  };\n}\n```\n\nWe must register this plugin in our Vuex Store:\n\n```typescript\n// src/store/index.ts\nimport Vue from \"vue\";\nimport Vuex from \"vuex\";\nimport createLogger from \"vuex/dist/logger\";\nimport createPersistedState from \"./plugins/persistent\";\n\nimport foo from \"./modules/foo\";\nimport bar from \"./modules/bar\";\n\nVue.use(Vuex);\n\n// Disable logs & strict mode in production:\nconst debug = process.env.NODE_ENV !== \"production\";\n\n// Plugins for both `development` & `production` modes:\nconst plugins = [\n  createPersistedState({\n    strictMode: debug,\n    // Specify here which modules should be persistent:\n    modules: [\"foo\", \"bar\"]\n  })\n];\n\n// Plugins for `development` mode:\nconst devPlugins = [\n  // Integrates with Vue Devtools:\n  createLogger()\n];\n\n// Plugins for `production` mode:\nconst prodPlugins = [];\n\nexport default new Vuex.Store({\n  strict: debug,\n  plugins: debug\n    ? [...plugins, ...devPlugins]\n    : [...plugins, ...prodPlugins],\n\n  modules: {\n    foo,\n    bar\n  }\n});\n```\n\nAnd voila! Data from foo and bar modules will be persistent, automatically stored, and retrieved in/from the local storage. The last thing we need to do is wait till the store is rehydrated before rendering the main app component, but since we are emitting a `storageReady` event in our `vuex-persist` wrapper, this should be pretty easy:\n\n```html\n<template>\n  <transition-group name=\"fade\" class=\"app\">\n    <Loader key=\"app-loader\" v-if=\"!isStateReady\" />\n    <Content key=\"app-content\" v-if=\"isStateReady\" />\n  </transition-group>\n</template>\n\n<script>\nimport Loader from \"./components/Loader.vue\";\nimport Content from \"./components/Content.vue\";\n\nexport default {\n  name: \"App\",\n  components: {\n    Loader,\n    Content\n  },\n\n  data: () => ({\n    isStateReady: false\n  }),\n\n  created() {\n    // This event is fired by the \"persistent\" Vuex plugin when the state is\n    // loaded from local storage (i.e. IndexedDB):\n    this.$store._vm.$root.$on(\"storageReady\", () => {\n      this.isStateReady = true;\n    });\n  }\n};\n</script>\n```\n\n## Testing offline-first applications\n\nGoogle Chrome’s DevTools offers a lot of functions to test the PWA features of your web application. However, some of them require HTTPS certificates, even on localhost. Let’s see how to properly set up a testing environment to test our Vue application.\n\n### Creating a development environment with HTTPS\n\nTo test service workers and other features locally, we will need to generate our own, self-signed certificate and add it to our OS’s trust store. This process is described on [letsencrypt page](https://letsencrypt.org/docs/certificates-for-localhost/) – it requires only the following command to generate certificates:\n\n```bash\nopenssl req -x509 -out localhost.crt -keyout localhost.key \\\n  -newkey rsa:2048 -nodes -sha256 \\\n  -subj \"/CN=localhost\" -extensions EXT -config <( \\\n   printf \"[dn]\\nCN=localhost\\n[req]\\ndistinguished_name = dn\\n[EXT]\\nsubjectAltName=DNS:localhost\\nkeyUsage=digitalSignature\\nextendedKeyUsage=serverAuth\")\n```\n\nOnce `localhost.crt` is installed and trusted on our machine, we can modify `vue.config.js` to use the generated certificates, as follows:\n\n```typescript\nconst fs = require(\"fs\");\n\nconst config = {};\n\nif (process.env.NODE_ENV === \"production\") {\n  config.devServer = {\n    https: {\n      key: fs.readFileSync(\"localhost.key\"),\n      cert: fs.readFileSync(\"localhost.crt\")\n    }\n  };\n}\n\nmodule.exports = config;\n```\n\nWe can add some utility scripts in our `package.json` to facilitate our work:\n\n```json\n{\n  \"scripts\": {\n    \"serve:prod\": \"vue-cli-service build --mode=production --watch & node ./serve.js\",\n    \"serve:dev\": \"vue-cli-service serve --mode=development\",\n    \"serve\": \"vue-cli-service serve\"\n  }\n}\n```\n\nNow, we can run:\n\n```bash\n$ npm run serve:prod\n```\n\n…and test our PWA here.\n\n### Testing the application in offline mode\n\nYou can test your Progressive Web Applications directly in the browser, without the need to manually disable network connections.\n\n1. Go to **Network** panel;\n2. Click **Offline** in the bar.\n\n### Testing the \"add to home screen\" experience\n\n1. Go to the **Application** panel;\n2. Go to the **Manifest** tab;\n3. Click **Add to home screen**.\n\n### Making a general Progressive Web App audit\n\n1. Go to the **Audits** panel (Lighthouse);\n2. Select **Progressive Web App**;\n3. Click **Run audits**.\n\n## Conclusion\n\nIn this article, we learned how to create a great base for offline-first, PWAs using Vue, web manifest, and other standards. There’s a lot more to consider to make a great native-like feeling and keep your user engaged. Here are some points to consider:\n- Keyboard shortcuts;\n- Notification & icon badges;\n","excerpt":"With JavaScript increasingly gaining popularity, Progressive Web Apps (PWAs) might replace native mobile & desktop apps in the future. In this post, we…","tableOfContents":{"items":[{"url":"#introduction-to-progressive-web-apps-pwas","title":"Introduction to Progressive Web Apps (PWAs)","items":[{"url":"#browser-support","title":"Browser support"}]},{"url":"#getting-started","title":"Getting started","items":[{"url":"#setting-up-a-service-worker","title":"Setting up a service worker"},{"url":"#prompting-the-user-to-install","title":"Prompting the user to install"},{"url":"#prompting-the-user-to-update","title":"Prompting the user to update"},{"url":"#handling-offline-first-forms","title":"Handling offline-first forms"},{"url":"#showing-offline-information","title":"Showing offline information"},{"url":"#making-vuex-state-persistent","title":"Making Vuex state persistent"}]},{"url":"#testing-offline-first-applications","title":"Testing offline-first applications","items":[{"url":"#creating-a-development-environment-with-https","title":"Creating a development environment with HTTPS"},{"url":"#testing-the-application-in-offline-mode","title":"Testing the application in offline mode"},{"url":"#testing-the-add-to-home-screen-experience","title":"Testing the “add to home screen” experience"},{"url":"#making-a-general-progressive-web-app-audit","title":"Making a general Progressive Web App audit"}]},{"url":"#conclusion","title":"Conclusion"}]},"fields":{"slug":"/blog/2019-01-05-creating-offline-first-vue-apps/","timeToRead":{"minutes":13.71,"words":2742}},"frontmatter":{"title":"Creating offline-first Progressive Web Applications in Vue","authors":["Bartosz Łaniewski"],"keywords":["Vue","PWA"],"language":"en","description":null,"dateCreated":"January 04, 2019","dateCreatedMeta":"2019-01-05 00:00:00 +0100","dateUpdated":"December 25, 2023","dateUpdatedMeta":"2023-12-26 00:00:00 +0100","datePublished":"January 04, 2019","datePublishedMeta":"2019-01-05 00:00:00 +0100"},"internal":{"contentFilePath":"/home/runner/work/bartozzz.github.io/bartozzz.github.io/content/blog/2019-01-05-creating-offline-first-vue-apps/index.md"}},{"id":"afb5b5a2-7917-5f76-bc42-4912cf350058","body":"\nMore than [240 000 repositories on GitHub](https://github.com/facebook/flow/network/dependents) use Flow, but only a few export Flow definitions. In this article, I’ll show you how to export Flow definitions for a module. Before starting, I encourage you to read my previous article about [publishing Tree Shaking-friendly packages to npm](/blog/2018-04-29-publishing-packages-to-npm/).\n\n## What is Flow?\n\nYou’ve probably already seen [Gary’s talk from CodeMash 2012](https://www.destroyallsoftware.com/talks/wat) about JavaScript. With Flow in your hands, there should be no more „_wat’s_”.\n\n> Flow is a static type checker for your JavaScript code. It does a lot of work to make you more productive. Making you code faster, smarter, more confidently, and to a bigger scale. – [Introduction to type checking with Flow](https://flow.org/en/docs/getting-started/)\n\nFlow was first presented at the [Scale Conference](https://atscaleconference.com/) in 2014 by Facebook. Its main goal was to add additional syntax to JavaScript language to prevent type errors and give developers a more concise idea about bugs that can occur in their code. It also offers a way for IDEs to provide a better environment for spotting errors in real-time.\n\n## How to export Flow definitions?\n\nThere are currently two ways to export Flow definitions. The easiest one is to include the source files within your package. All you have to do is change their extension to `.js.flow` and include them with the bundle.\n\n### Exporting Flow files\n\nLet’s start by installing the required npm dependencies using the following command:\n\n```bash\n$ npm install --save-dev glob fs-extra\n```\n\nOnce installed, we can write a script that will copy all source files to the `/dest` directory and change their extension to `.js.flow`:\n\n```javascript\n// ./scripts/copy-flow-definitions.js\nimport { basename, resolve } from \"path\";\nimport { copy } from \"fs-extra\";\nimport glob from \"glob\";\n\nasync function copyFile(file) {\n  const srcDir  = resolve(__dirname, \"../src\");\n  const destDir = resolve(__dirname, \"../dest\");\n  const fileDef = `${file}.flow`.replace(srcDir, destDir);\n\n  await copy(file, fileDef);\n\n  console.log(`Copied ${file} to ${fileDef}`);\n}\n\nglob(resolve(__dirname, \"../src/**/*.js\"), (err, files) => {\n  files.forEach(file => copyFile(file));\n});\n```\n\nThen, you can execute this script at the end of your build pipeline as follows:\n\n```json\n{\n  \"scripts\": {\n    \"build\": \"npx babel ./src -d ./dest\",\n    \"postbuild\": \"node ./scripts/copy-flow-definitions.js\"\n  }\n}\n```\n\n<Newsletter />\n\n### Adding definitions to flow-typed\n\nIf you plan to version your definitions, you should contribute to the `flow-typed` repository instead. Flow supports library definitions, which allow you to describe the interface of a module or library separately from the implementation of that module/library.\n\nYou can add your definitions by [contributing library definitions](https://flow-typed.github.io/flow-typed/#/?id=how-do-i-contribute-library-definitions) to the `flow-typed` repository. It will allow people who use your library to fetch definitions by using the following command:\n\n```bash\n$ flow-typed install library@x.x.x\n```\n\n## Conclusion\n\nIt is important to export Flow definitions so Flow can give errors if someone accidentally misuses your library. Additionally, it integrates well with most IDEs, giving developers a better experience by providing real-time documentation, auto-complete, and pointing mistakes.\n","excerpt":"More than 240 000 repositories on GitHub use Flow, but only a few export Flow definitions. In this article, I’ll show you how to export Flow definitions…","tableOfContents":{"items":[{"url":"#what-is-flow","title":"What is Flow?"},{"url":"#how-to-export-flow-definitions","title":"How to export Flow definitions?","items":[{"url":"#exporting-flow-files","title":"Exporting Flow files"},{"url":"#adding-definitions-to-flow-typed","title":"Adding definitions to flow-typed"}]},{"url":"#conclusion","title":"Conclusion"}]},"fields":{"slug":"/blog/2018-05-13-exporting-flow-definitions-to-npm/","timeToRead":{"minutes":2.365,"words":473}},"frontmatter":{"title":"How to export Flow definitions in npm packages?","authors":["Bartosz Łaniewski"],"keywords":["JavaScript","Flow","npm"],"language":"en","description":null,"dateCreated":"May 12, 2018","dateCreatedMeta":"2018-05-13 00:00:00 +0100","dateUpdated":"April 07, 2024","dateUpdatedMeta":"2024-04-07 11:00:00 +0100","datePublished":"May 12, 2018","datePublishedMeta":"2018-05-13 00:00:00 +0100"},"internal":{"contentFilePath":"/home/runner/work/bartozzz.github.io/bartozzz.github.io/content/blog/2018-05-13-exporting-flow-definitions-to-npm/index.md"}},{"id":"6198e53d-3784-5a9e-8e80-e40f4f623c58","body":"\nWith the rise of ES2015, modules have officially become an integral part of JavaScript. By their nature, ES2015 modules are static and can be optimized at the compile time. Various tools and techniques have been created to minimize the total size of generated bundles. The one described in this article is called tree shaking.\n\n## Introduction to npm packages\n\n**npm** is the most popular package manager for JavaScript. It is shipped by default with Node.js – the JavaScript runtime environment. Each month, there are over [20 billion downloads](https://www.npmjs.com/) from the npm registry, which counts more than half a million different packages.\n\n### How does bundling work?\n\nA package is a directory described by a `package.json`. Each package is composed of one or more modules that can be loaded by Node.js’ `require()`. A package usually exposes a single module via the `main` field specified in `package.json`. If there’s no such field, npm will look for `index.js` in the root directory.\n\n\nMost bundlers (such as [Webpack](https://webpack.js.org/) or [Browserify](https://browserify.org/)) will output a unique JavaScript file when building the package. For example, let’s consider the following code:\n\n```javascript\n// Entry point: index.js\nexport * as moduleA from \"./src/moduleA\";\nexport * as moduleB from \"./src/moduleB\";\nexport * as moduleC from \"./src/moduleC\";\n```\n\nWebpack will start by compiling the source file (called _entry point_). It will then move from `import` to `import` and include every required file in the build pipe. It will generate a single bundle containing all the imported modules as follows:\n\n```javascript\n(function (modules) {\n  // Webpack stuff\n})({\n  \"./index.js\": function (module, exports, __webpack_require__) {\n    \"use strict\";\n    // Compiled entry-point\n  },\n  \"./src/moduleA.js\": function (module, exports, __webpack_require__) {\n    \"use strict\";\n    // Compiled moduleA\n  },\n  \"./src/moduleB.js\": function (module, exports, __webpack_require__) {\n    \"use strict\";\n    // Compiled moduleB\n  },\n  \"./src/moduleC.js\": function (module, exports, __webpack_require__) {\n    \"use strict\";\n    // Compiled moduleC\n  },\n});\n```\n\nOnce published to npm, each module can be loaded using Node.js’ `require()` (or [ES2015 `import`](https://tc39.es/ecma262/#sec-imports)) as follows:\n\n```javascript\nimport { moduleA, moduleB, moduleC } from \"package\";\n\nmoduleA.method();\nmoduleB.method();\nmoduleC.method();\n```\n\nSuch bundlers can work because [ES2015 packages are static by nature][1]: you can predict which modules are being imported and exported just by analyzing the code without the need to execute it. However, this has some drawbacks:\n\n- **conditional imports and exports** are unsupported – you have to declare your imports at the top level;\n- both imports and exports **cannot have any dynamic parts** – you cannot use string concatenation in `require()`.\n\n### What is tree shaking?\n\nTree shaking is a script that performs code analysis for a given bundle and checks which modules are never used at the **compile (build) time**. Let’s take the previous example:\n\n```javascript\nimport { moduleA, moduleB } from \"package\";\n```\n\n`package` exports `moduleA`, `moduleB`, and `moduleC`, but only the first two are imported. Without tree shaking, the final bundle would contain unreachable code (`moduleC`). Unused exports can be removed during bundling, potentially resulting in significant space savings.\n\n> Utilizing the tree shaking and dead code elimination can significantly reduce the code size we have in our application. The less code we send over the wire the more performant the application will be. – [Alex Bachuk](https://medium.com/@netxm/what-is-tree-shaking-de7c6be5cadd).\n\n<Newsletter />\n\n## Creating tree shaking-friendly packages\n\nOur goal will be to expose multiple module bundles from a single package so one can `import` only necessary parts instead of the entire library:\n\n```javascript\nimport * as moduleA from \"package/moduleA\";\nimport * as moduleB from \"package/moduleB\";\nimport { funcA, funcB } from \"package/moduleC\";\n```\n\n- If we import only `moduleA`, the two other modules will not be included in the final bundle because they aren’t required anywhere.\n- If we import only a specific function from a module (ex. `funcA`), the rest of the module’s content will be ignored.\n\nWe don’t have to access a named export like in previous examples. That means we don’t have to do a slow, dynamic property lookup. In our case, we know the content and can optimize the access.\n\n### Directory structure overview\n\n```\n├── scripts/\n│   └── copy.js\n├── package/\n│   └── package.json\n├── source/\n│   ├── moduleA/\n│   ├── moduleB/\n│   ├── moduleC/\n│   └── index.js\n└── package.json\n```\n\n- `scripts/` will contain all JavaScript binaries that will be used to build your package.\n- `package/` directory is where your package will reside once it is compiled. It is the directory that will be pushed to the npm registry.\n- `source/` directory is where your package source resides. It will not be pushed to the npm registry but should be in the repository.\n\nAs you can see, there are two `package.json` files. The one at the root will be used to declare your dependencies, metadata, and scripts. The second one will be pushed to the npm registry. It will get generated automatically and populated with more fields, such as `main`.\n\n### Compiling and building the package\n\nIn this article, we will use [Babel](https://babeljs.io/) for the compilation process. Babel is a JavaScript transpiler that converts ECMAScript and other JavaScript subsets into plain JavaScript that can be used in any environment. First, you need to install Babel as a development dependency in your project:\n\n```bash\n$ npm install --save-dev babel-cli\n```\n\nFor in-depth installation details, I encourage you to check [Babel’ setup section in their documentation](https://babeljs.io/setup/). Once Babel is installed, we can define a few scripts in `/package.json`:\n\n```json\n{\n  \"private\": true,\n  \"dependencies\": {\n    \"rimraf\": \"^5.0.5\",\n    \"fs-extra\": \"^11.2.0\"\n  },\n  \"scripts\": {\n    \"clean\": \"npx rimraf ./package/*\",\n    \"build\": \"npx babel ./source --out-dir ./package\",\n    \"copy\": \"npx babel-node ./scripts/copy.js\"\n  }\n}\n```\n\n- `npm run clean` will remove built modules from the `/package` directory.\n- `npm run build` will build modules and pipe the bundles to the `/package` directory.\n- `npm run copy` will execute the `/scripts/copy.js` script described in the next section.\n\n<Alert type=\"info\">\n  It is important to set `private` to `true` in `/package.json` to prevent you from accidentally pushing your entire repository to the npm registry instead of only the build.\n</Alert>\n\n### Copying required files into the package\n\nThe script below will copy meta files such as `README.md` and `LICENSE` to your final package. Additionally, it will create a brand new `package.json`.\n\n```javascript\n// File: /scripts/copy.js\nimport { basename, resolve } from \"path\";\nimport { copy, writeFile } from \"fs-extra\";\n\nasync function copyFile(file) {\n  const fileName = basename(file);\n  const filePath = resolve(__dirname, \"../package/\", fileName);\n\n  await copy(file, filePath);\n\n  console.log(`Copied ${file} to ${filePath}`);\n}\n\nasync function createPackageFile() {\n  const oldPackagePath = resolve(__dirname, \"../package.json\");\n  const oldPackageData = require(oldPackagePath);\n\n  delete oldPackageData.private;\n  delete oldPackageData.scripts;\n  delete oldPackageData.devDependencies;\n\n  const newPackagePath = resolve(__dirname, \"../package/package.json\");\n  const newPackageData = Object.assign(oldPackageData, { main: \"./index.js\" });\n  await writeFile(newPackagePath, JSON.stringify(newPackageData), \"utf8\");\n\n  console.log(`Created package.json in ${newPackagePath}`);\n}\n\nasync function run() {\n  await copyFile(\"README.md\");\n  await copyFile(\"LICENSE\");\n  await createPackageFile();\n}\n\nrun();\n```\n\n## Limitations and solutions\n\nTree shaking is a relatively new technology and still has some limitations. While not every single one can be resolved directly in tree shaking, there are various ways around these problems.\n\n### Side effects in module bundles\n\nSome modules have side effects: they can perform additional tasks, such as modifying global variables instead of just exporting their content. According to the ECMAScript specifications, all child modules must be evaluated because they could contain side effects. Let’s take the following examples:\n\n```javascript\n// moduleA\nconsole.log(\"Side effect\");\n\nexport {/* … */};\nexport default /* … */;\n```\n\n```javascript\n// moduleB\nwindow.a = /* … */;\nwindow.b = /* … */;\nwindow.c = /* … */;\n```\n\nBecause of this potential behavior, tree shaking cannot remove all unreachable code. However, some bundlers, such as Webpack, drop the responsibility on the developers by providing a `sideEffect` option. By setting this flag to `false`, you indicate that your package is a _pure module_ and doesn’t have any side effects. Therefore, it can be aggressively optimized.\n\n### Wrong specs implementation\n\n> Current tooling differs on the correct way to handle default imports/exports. Avoiding them all together can help avoid tooling bugs and conflicts. – [TSLint rules][6]\n\n### Class-based tree shaking\n\nClass-based tree shaking is currently not supported because of the dynamic nature of JavaScript’s property accessors – they cannot be statically determined, especially when using bracket notation. Let’s consider the following example:\n\n```javascript\nconst bar = new Foo();\n\nbar.methodA();\nbar[\"methodB\"]();\nbar[`method${n}`]();\nbar[\"methodD\".split(\"\").reverse().join(\"\")]();\n```\n\nAs you can see, `methodA` and `methodB` can be statically determined as being used at compile time, but this is not true for the last two cases. There are different proposals to improve tree shaking in classes.\n\n#### Bind operator proposal\n\n> The :: operator creates a bound function such that the left hand side of the operator is bound as the this variable to the target function on the right hand side. By providing syntactic sugar for these use cases we will enable a new class of \"virtual method\" library, which will have usability advantages over the standard adapter patterns in use today. – [tc39/proposal-bind-operator][2]\n\n```javascript\nimport Foo, { methodA, methodB } from \"foo\";\n\nconst bar = new Foo();\nbar::methodA();\nbar::methodB();\n```\n\n#### Pipeline operator proposal\n\n> This proposal introduces a new operator \\|\\> similar to _F#, OCaml, …, Hack and LiveScript_, as well as UNIX pipes. It’s a backwards-compatible way of streamlining chained function calls in a readable, functional manner, and provides a practical alternative to extending built-in prototypes. – [tc39/proposal-pipeline-operator][3]\n\n```javascript\nimport Foo, { methodA, methodB } from \"foo\";\n\nconst bar = new Foo();\nbar |> methodA();\nbar |> methodB();\n```\n\n## Resources\n\n1. [Exploring JS – Static module structure][1]\n2. [ECMAScript – This-Binding Syntax][2]\n3. [ECMAScript – The Pipeline Operator][3]\n4. [Rollup – Tree shaking documentation][4]\n5. [Webpack – Tree shaking documentation][7]\n6. [Rollup vs Webpack2 – David Rodenas][5]\n\n[1]: https://exploringjs.com/es6/ch_modules.html#static-module-structure \"Exploring JS – Static module structure\"\n[2]: https://github.com/tc39/proposal-bind-operator \"ECMAScript This-Binding Syntax\"\n[3]: https://github.com/tc39/proposal-pipeline-operator \"ESNext Proposal: The Pipeline Operator\"\n[4]: https://rollupjs.org/guide/en#tree-shaking \"Rollup – Tree shaking documentation\"\n[5]: http://david-rodenas.com/posts/rollup-vs-webpack-and-tree-shaking \"Rollup vs. Webpack – Tree shaking\"\n[6]: https://palantir.github.io/tslint/rules/no-default-export/ \"TSLint rules – no default export\"\n[7]: https://webpack.js.org/guides/tree-shaking/ \"Webpack – Tree shaking documentation\"\n","excerpt":"With the rise of ES2015, modules have officially become an integral part of JavaScript. By their nature, ES2015 modules are static and can be optimized at…","tableOfContents":{"items":[{"url":"#introduction-to-npm-packages","title":"Introduction to npm packages","items":[{"url":"#how-does-bundling-work","title":"How does bundling work?"},{"url":"#what-is-tree-shaking","title":"What is tree shaking?"}]},{"url":"#creating-tree-shaking-friendly-packages","title":"Creating tree shaking-friendly packages","items":[{"url":"#directory-structure-overview","title":"Directory structure overview"},{"url":"#compiling-and-building-the-package","title":"Compiling and building the package"},{"url":"#copying-required-files-into-the-package","title":"Copying required files into the package"}]},{"url":"#limitations-and-solutions","title":"Limitations and solutions","items":[{"url":"#side-effects-in-module-bundles","title":"Side effects in module bundles"},{"url":"#wrong-specs-implementation","title":"Wrong specs implementation"},{"url":"#class-based-tree-shaking","title":"Class-based tree shaking"}]},{"url":"#resources","title":"Resources"}]},"fields":{"slug":"/blog/2018-04-29-publishing-packages-to-npm/","timeToRead":{"minutes":8.225,"words":1645}},"frontmatter":{"title":"How to publish a Tree Shaking friendly npm package?","authors":["Bartosz Łaniewski"],"keywords":["JavaScript","npm"],"language":"en","description":null,"dateCreated":"April 28, 2018","dateCreatedMeta":"2018-04-29 00:00:00 +0100","dateUpdated":"April 06, 2024","dateUpdatedMeta":"2024-04-07 00:00:00 +0100","datePublished":"April 28, 2018","datePublishedMeta":"2018-04-29 00:00:00 +0100"},"internal":{"contentFilePath":"/home/runner/work/bartozzz.github.io/bartozzz.github.io/content/blog/2018-04-29-publishing-packages-to-npm/index.md"}},{"id":"bfcde81c-c691-5355-a276-205137baa362","body":"\nLe Bitcoin est l’une des premières cryptomonnaies utilisant un réseau de type paire-à-paire et des systèmes cryptographiques sophistiqués. Elle est aujourd’hui évaluée à une valeur nette de plus de [185 milliards de dollars][1]. Ce document traitera des origines du Bitcoin, mais aussi de l’implémentation des technologies utilisées dans cette monnaie.\n\n## Les origines du Bitcoin\n\nLes origines du Bitcoin remontent à fin 2008. En août, le nom de domaine [bitcoin.org est enregistré][2] et c’est le 1<sup>er</sup> novembre 2008 qu’est publié le livre blanc qui pose les bases de la crypto-monnaie. Nommé [«_Bitcoin: un système de monnaie électronique paire-à-paire_»][3], c’est dans celui-ci qu’est évoqué pour la première fois un système monétaire entièrement [décentralisé et sécurisé][4]. Le livre blanc fut ensuite posté sur une mailing list dédiée à la cryptographie pendant la même période. C’est ici que le projet attira l’attention des spécialistes du milieu.\n\n### L’auteur du Bitcoin: Satoshi Nakamoto\n\nSatoshi Nakamoto, l’auteur du Bitcoin, reste encore inconnu à ce jour. Il pourrait aussi bien s’agir d’une seule personne que d’un groupe de plusieurs personnes disséminées à travers le monde. Son profil, tel qu’il apparaît sur un site traitant des systèmes pair-à-pair ([_P2P Foundation_](https://p2pfoundation.ning.com/profile/SatoshiNakamoto)), indique qu’il s’agit d’un homme d’origine japonaise. Toutefois, ces informations pourraient très bien être fabriquées – son anglais parfait remet en question ses origines. De plus, aucune preuve concrète n’a jamais été donnée quant à son identité.\n\nIl a miné les 50 premiers Bitcoins dans le _genesis block_ – un bloc unique en ce qu’il ne contient aucune référence à un bloc précédent. Ainsi, les transactions faites jusqu’à ce jour intègrent l’historique de chaque transaction effectuée depuis ce premier bloc. Il est aussi la première personne à émettre une transaction le 3 janvier 2009.\n\nS’il est l’inventeur du Bitcoin et a écrit le code source originel, Satoshi Nakamoto s’est aujourd’hui détaché du projet; les dernières traces de son travail datant de décembre 2010. Toutefois, avant de disparaître, Nakamoto donna les reines du projet au développeur Gavin Andresen qui créa la Bitcoin Foundation en 2012.\n\n### La reconnaissance dans le monde\n\nLe Bitcoin est aujourd’hui une monnaie acceptée par un nombre considérable d’acteurs économiques. C’est même la monnaie de prédilection pour un certain nombre d’échanges pour lesquels l’anonymat et la discrétion sont de mise. Ainsi, de nombreux organismes firent figure [d’_early adopters_][5] et, très tôt, prirent en charge le Bitcoin, notamment: _l’EFF_, _Wikileaks_, _Internet Archive_ et al. Dès 2012, [plus d’un millier][6] de marchand prenaient ainsi en charge le protocole. Des entreprises à portée massive telles que _Baidu_ ou _Zynga_ commencent à accepter le Bitcoin à la même période. _Newegg_, _Dell_, _Microsoft_, _Steam_, _Barclays_, _Uber_ et al. ont successivement accepté le Bitcoin dans les années à venir.\n\nDébut 2017, le Japon passe une loi donnant au Bitcoin le statut de devise pouvant être utilisée légalement pour n’importe quel échange. Par la suite, en janvier 2018, le gouvernement sud-coréen fait passer une régulation obligeant chaque commerçant et client à révéler leur identité mettant ainsi fin à la possibilité d’échanger des Bitcoins de manière anonyme dans le pays.\n\nToutefois, plusieurs événements mettant en cause la force du Bitcoin ont eu lieu. Ainsi, en août 2017 le Bitcoin est séparé en deux devises différentes: le Bitcoin (_BTC_) et Bitcoin Cash (_BCH_). _Steam_, _Stripe_ et d’autres entreprises ont annoncé en fin d’année 2017 supprimer graduellement la possibilité d’effectuer des transactions en Bitcoin. Les principales raisons évoquées étant les coûts de transaction de plus en plus élevés et un temps de complétion des transactions beaucoup trop lent, même si la puissance consacrée au minage était de [8000000 tera-hash par seconde][7]:\n\n> La puissance globale consacrée aujourd’hui au minage de Bitcoins est de 2250000 pétaflops. C’est plus de 20000 fois la puissance du plus puissant ordinateur du monde (le «Tianhe-2» détenu par la Chine qui espère atteindre en 2015 une puissance de 100 pétaflops) et c’est largement plus de cent fois la puissance cumulée des 500 ordinateurs les plus puissants. – Jean-Paul Delahaye\n\n---\n\n## Point de vue économique\n\nLe marché du Bitcoin est perçu, selon une majeure partie des économistes, comme une bulle spéculative. En effet, son prix peut doubler [d’un jour à l’autre][8]. D’autres, voient les crypto-monnaies comme le seul moyen de stocker son argent sans crainte d’inflation et création artificielle de monnaie par les banques centrales. Cependant, tout le monde est d’accord sur le fait qu’il s’agit d’un marché relativement [jeune et instable][9], exigeant une observation constante du prix et une approche avec du recul.\n\n### Les débuts du Bitcoin sur le marché\n\nLe Bitcoin est [l’une des premières][7] crypto-monnaies crées. C’est aussi la première crypto-monnaie qui eu un succès au niveau international. Pour bien expliquer le phénomène du Bitcoin, il faut remonter à 2008, quand l’une des plus grandes crises financières s’est produite. Des dizaines de devises ont commencé à perdre de leur valeur – les méthodes traditionnelles d’évaluation monétaire et leur dépendance ont contribuées à une [catastrophe économique][10].\n\nÀ cette periode, la monnaie virtuelle semblait être une idée abstraite d’Internet. Cela se voyait particulièrement avec les faibles cotations du Bitcoin quand il a fait ses débuts sur le marché boursier de [_MtGox_][11] et ne valait que 0.063 USD par unité. Le Bitcoin était alors la seule monnaie ne pouvant pas être confisquée par les forces d’état (gouvernements, banques, huissiers de justice, etc.). Il fournissait une garantie de possession d’argent qui s’avéra particulièrement utile dans les pays les plus touchés par la crise comme la Grèce.\n\n> If people lose faith in a currency, the typical reaction is to start using another one. Traditionally, money has simply flung to the most stable currency, which has typically been the dollar. But Bitcoin has a couple of advantages over old-fashioned cash. The first advantage is that it is not controlled by any central authority. In countries where people are increasingly distrustful of how central banks and governments manage the economy, Bitcoin may seem like a more sensible alternative. ~ [Danny Bradbury][18]\n\n### Comparaison avec les monnaies classiques\n\nL’argent est une marchandise reconnue comme le résultat d’un consentement général et en tant que moyen d’échange économique. L’argent est donc tout ce qui fait l’objet d’un contrat entre deux personnes et est échangeable contre d’autres biens. C’est par exemple le cas des billets de banque ou encore des virements électroniques. Chaque monnaie doit se soumettre à trois règles:\n\n1. Il doit être possible de montrer qu’**une somme d’argent appartient à son propriétaire**.\n2. Il doit être possible de **transférer une somme d’argent** d’un propriétaire à un autre.\n3. Après le transfert, le propriétaire d’origine **perd le droit sur la somme transférée**.\n\nLe Bitcoin vérifie toutes ces règles et résout plus efficacement d’autres problèmes grâce à des mécanismes mathématiques et cryptographiques:\n\n- **Sécurité.**\n  Au cœur des crypto-monnaies se trouve une technologie nommée _blockchain_. Il s’agit d’un système qui joue le rôle du registre des transactions. Il peut être imaginé comme un livre de comptabilité collectif diffus dans le réseau. Il est ouvert à tous, mais ne peut être corrompu, car il est protégé par des outils cryptographiques puissants. Une fois une transaction enregistrée dans le registre, elle ne peut pas être annulée.\n- **Anonymat.**\n  L’émetteur et le destinataire sont identifiés par une [clé publique][12] mais leur vraie identité n’est connue de personne à part eux. En tant qu’utilisateur, nous ne sommes donc qu’une chaîne de caractères et de nombres aux yeux des autres internautes. Il n’y a aucun moyen de retrouver notre vraie identité en s’appuyant sur les <abbr title=\"Valeur de sortie d’une fonction de hachage cryptographique, c’est-à-dire une fonction qui à une donnée de taille arbitraire, associe une image de taille fixe, et dont une propriété essentielle est qu’elle est pratiquement impossible à inverser.\">hash</abbr> du registre public qui sont gérés par la _blockchain_.\n- **Divisibilité.**\n  Le prix d’un Bitcoin dépasse le budget de la plupart des personnes qui sont potentiellement intéressées dans son achat. Le grand avantage du Bitcoin est sa divisibilité. Ainsi, il est possible d’acheter 0,00000001 BTC ([jusqu’à 8 chiffres après la virgule][13]).\n- **Décentralisation.**\n  Les crypto-monnaies reposent sur un système informatique décentralisé (de type pair-à-pair) et souvent avec un code source publié sous une licence libre ([MIT][14] pour le Bitcoin). Tout le monde peut utiliser sa machine pour aider à améliorer l’infrastructure.\n- **Facilité de transferts.**\n  Il est possible d’effectuer des transferts d’argent dans le monde entier à un prix très bas. Le coût de transaction est redistribué entre les «mineurs» une fois la transaction validée. En moyenne, un transfert dure 30 minutes ([jusqu’à 16 heures dans les cas extrêmes][15]). Plus le coût de transaction est grand, plus vite le transfert est effectué.\n\nLe Bitcoin est une technologie révolutionnaire qui va changer le monde de la finance, tout comme l’e-mail a changé la façon dont les gens communiquent.\n\n<Newsletter />\n\n---\n\n## Fonctionnement et réseau\n\nDans cette partie, nous verrons comment est stocké l’argent sur un portefeuille virtuel et comment sont vérifiés les transferts. D’un premier coup d’œil, c’est simple – la _blockchain_ vérifie une par une toutes les transactions et compte combien d’argent a été stocké et dépensé sur l’adresse d’un portefeuille. Si on a reçu assez de Bitcoins sur notre clé publique, le transfert peut être réalisé. En réalité, c’est un mécanisme beaucoup plus complexe.\n\n### Blockchain\n\nLa _blockchain_ est une technologie basée sur un réseau de type pair-à-pair (sans serveur central) qui sert d’une interface entre notre base de données locale et les bases de données des autres peers. Chaque machine dans le réseau peut participer à la création de la _blockchain_. Ce système forme une chaîne de blocs qui sont connectés les uns aux autres. Chaque bloc contient plusieurs informations. Dans le cas des monnaies virtuelles, les plus importantes sont:\n\n1. le **nombre total** de transactions qui ont été enregistrées dans le bloc;\n2. le **détail** de chaque transaction enregistrée;\n3. le **hash** du bloc précédent;\n\nUne fois qu’un bloc est rempli avec un nombre de transactions suffisant, d’autres blocs sont créés et une véritable structure de chaîne apparaît. En 2017, un nouveau bloc est créé toutes les 10 minutes en moyenne.\n\n#### Implementation basique\n\n```js\nclass Block {\n  constructor(index, previousHash, data) {\n    // Le numéro du bloc\n    this.index = index;\n    // Transactions\n    this.data = data;\n    // Date de création\n    this.date = new Date();\n    // Le hash du bloc précédent\n    this.prevHash = previousHash;\n  }\n\n  get hash() {\n    return sha256(\n      this.index + this.date + this.prevHash + JSON.stringify(this.data)\n    );\n  }\n}\n\nclass Blockchain {\n  constructor(genesisBlock) {\n    // Le bloc initial, sans référence au bloc précédent\n    this.blockchain = [genesisBlock];\n  }\n\n  addBlock(data) {\n    const index = this.blockchain.length;\n    const oldBlock = this.blockchain[index - 1];\n    const newBlock = new Block(index, oldBlock.hash, data);\n\n    if (this.checkValidity(newBlock, oldBlock)) {\n      this.blockchain.push(newBlock);\n    }\n  }\n\n  checkValidity(newBlock, oldBlock) {\n    if (newBlock.index !== oldBlock.index + 1) {\n      throw new Error(\"Invalid index\");\n    }\n\n    if (newBlock.previousHash !== oldBlock.hash) {\n      throw new Error(\"Invalid hash\");\n    }\n\n    return true;\n  }\n\n  checkIntegrality() {\n    for (let i = 1; i < this.blockchain.length; i++) {\n      const prev = this.blockchain[i - 1];\n      const next = this.blockchain[i];\n\n      if (!this.checkValidity(next, prev)) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n}\n```\n\n#### Synchronisation des bases de données\n\nLa synchronisation de notre base de données locale avec les bases de données des autres paires connectés au réseau n’est pas une tâche triviale. Le protocole de réplication doit assurer:\n\n- **la cohérence**, c’est-à-dire la capacité de notre système à refléter sur la copie d’une donnée les modifications intervenues sur d’autre copies de cette donnée;\n- **la scalabilité**, c’est-à-dire la capacité de notre système à s’adapter à un changement d’ordre de grandeur de la demande, en particulier sa capacité à maintenir ses fonctionnalités et ses performances en cas de forte demande.\n\nIl s’agit d’une communication à double-sens: notre système doit envoyer toutes les modifications pour les inclure dans la blockchain principale et fusionner les changements rencontrés chez les autres pairs pour les inclure dans la blockchain locale. À notre rescousse viennent les «_Gossip protocols_».\n\nL’information se propage comme une épidémie dans le réseau en _O(log(n))_. L’implementation de ce protocole est décrite par Robbert van Renesse, Dan Dumitriu, Valient Gough et Chris Thomas dans leur publication [«_Efficient Reconciliation and Flow Control for Anti-Entropy Protocols_»][19]:\n\n> With few limitations, updates spread in expected time that grows logarithmic in the number of participating hosts, even in the face of host failures and message loss. The behavior of update propagation is easily modeled with well-known epidemic analysis techniques. As a result, many distributed applications use gossip to contain various inconsistencies.\n\n### Transactions\n\nDans la _blockchain_, toute information est publique. C’est l’une des caractéristiques révolutionnaires de la _blockchain_ qui fait tout son intérêt – chaque transaction (partie élémentaire d’un bloc) peut être vérifiée par n’importe qui, sans banque centrale. L’implémentation la plus simple pourrait être:\n\n```\nJean envoie 5 BTC a Pierre\n…\nMarie envoie 2 BTC a Lucie\n```\n\nPour vérifier que c’est bien Jean et Marie qui ont envoyé de l’argent, dans chaque transaction on ajoute une signature ([digital signature][16]) générée par notre portefeuille. Il s’agit d’un système cryptographique classique appelé [<abbr title=\"Le chiffrement RSA (nommé par les initiales de ses trois inventeurs) est un algorithme de cryptographie asymétrique, très utilisé dans le commerce électronique, et plus généralement pour échanger des données confidentielles sur Internet.\">RSA</abbr>][17]. À notre compte est attribué une clé privée (_q_) et une clé publique (_p_). Ce sont de grand nombres premiers, issus d’une courbe elliptique. De plus, nous disposons du hash (_h_) de la transaction.\n\n#### Vérification de la signature\n\nNous disposons de 3 nombres:\n\n- q: clé privée, connue par le propriétaire du portefeuille;\n- p: clé publique, utilisée pour effectuer des transactions;\n- h: hash de la transaction;\n\nPour calculer une signature, il est nécessaire d’utiliser les 3 nombres et masquer la clé privée. Pour cela, on effectue l’opération suivante:\n\n<p style={{ textAlign: \"center\" }}>N = p × q</p>\n\nAinsi on obtient un 4<sup>eme</sup> nombre contenant la clé privée cachée. Avec les moyens technologiques dont nous disposons aujourd’hui, il est impossible d’extraire cette clé sans la connaître à l’avance. Il est cependant très facile de vérifier, si (_N_) cache bien notre clé privée en effectuant l’opération inverse:\n\n<p style={{ textAlign: \"center\" }}>q = N / p</p>\n\nPour calculer la signature (_s_), nous effectuons une dernière opération:\n\n<p style={{ textAlign: \"center\" }}>s = h × N</p>\n\nPour vérifier les transactions on utilise les propriétés du système RSA. Il est ainsi possible de vérifier que l’auteur de la transaction est en possession de la clé privée qui correspond à sa clé publique et donc que c’est lui qui a effectué la transaction. Le champ data d’un bloc peut ressembler à celui-ci:\n\n```json\n{\n  \"receiver\": \"1HPs4CYgxpR3MP4…kfBciJBfKLUT\",\n  \"sender\": \"14uGXpDoZxFsjzT…R4mLi8ay4aAy\",\n  \"amount\": \"0.0015\",\n  \"N\": \"12S…036\",\n  \"h\": \"11bf52e5ef03cb40d7473…5266df0360fcd613fdc6b85\",\n  \"s\": \"809…fc4\"\n}\n```\n\n---\n\n## Resources\n\n1. [“Bitcoin - a Step Toward Censorship-Resistant Digital Currency” – Rainey Reitman][5]\n2. [”BitPay Signs 1,000 Merchants to Accept Bitcoin Payments” – Brian Browdie][6]\n3. [“Le Bitcoin, première crypto-monnaie” – Jean-Paul Delahaye][7]\n4. [“The price of bitcoin has doubled in two weeks“ – Lucas Matney][8]\n5. [“Why Is Bitcoin’s Value So Volatile” – Jonathan Todd Barker][9]\n6. [“Terrorist Use of Cyberspace and Cyber Terrorism: New Challenges and Responses” – M.N. Ogun][11]\n7. [“Bitcoin public and private keys” – Prypto][12]\n8. [“How long do Bitcoin transactions take?“ – Steven Buchko][15]\n9. [“Efficient Reconciliation and Flow Control for Anti-Entropy Protocols“ – Robbert van Renesse][19]\n\n[1]: https://coinmarketcap.com\n[2]: https://whois.com/whois/bitcoin.org\n[3]: https://satoshi.nakamotoinstitute.org/emails/cryptography/\n[4]: https://nakamotoinstitute.org/literature/\n[5]: https://eff.org/deeplinks/2011/01/bitcoin-step-toward-censorship-resista \"“Bitcoin - a Step Toward Censorship-Resistant Digital Currency” – Rainey Reitman\"\n[6]: https://americanbanker.com/news/bitpay-signs-1-000-merchants-to-accept-bitcoin-payments \"”BitPay Signs 1,000 Merchants to Accept Bitcoin Payments” – Brian Browdie\"\n[7]: https://www.societe-informatique-de-france.fr/wp-content/uploads/2014/10/1024-4-delahaye.pdf \"“Le Bitcoin, première crypto-monnaie” – Jean-Paul Delahaye\"\n[8]: https://techcrunch.com/2017/12/07/the-price-of-bitcoin-has-doubled-in-two-weeks-now-above-16k/ \"“The price of bitcoin has doubled in two weeks“ – Lucas Matney\"\n[9]: https://www.investopedia.com/articles/investing/052014/why-bitcoins-value-so-volatile.asp \"“Why Is Bitcoin’s Value So Volatile” –  Jonathan Todd Barker\"\n[10]: https://fr.wikipedia.org/wiki/Crise_bancaire_et_financi%C3%A8re_de_l%27automne_2008 \"Crise bancaire et financière de l’automne 2008\"\n[11]: https://books.google.fr/books?id=oPboDAAAQBAJ&lpg=PA47&vq=3.%20the%20fall%20of%20mt.%20gox&dq=mt.%20gox%2070&pg=PA47&q=3.%20the%20fall%20of%20mt.%20gox \"“Terrorist Use of Cyberspace and Cyber Terrorism: New Challenges and Responses” – M.N. Ogun\"\n[12]: https://www.dummies.com/article/business-careers-money/personal-finance/cryptocurrency/bitcoin-public-private-keys-223627/ \"“Bitcoin public and private keys” – Prypto\"\n[13]: https://en.bitcoin.it/wiki/Satoshi_(unit) \"Satoshi (unit)\"\n[14]: https://github.com/bitcoin/bitcoin/blob/master/COPYING \"Bitcoin License\"\n[15]: https://coincentral.com/how-long-do-bitcoin-transfers-take/ \"“How long do Bitcoin transactions take?“ – Steven Buchko\"\n[16]: https://fr.wikipedia.org/wiki/Signature_num%C3%A9rique \"Signature numérique\"\n[17]: https://fr.wikipedia.org/wiki/Chiffrement_RSA \"Chiffrement RSA\"\n[18]: https://thebalance.com/is-bitcoin-the-answer-in-a-financial-crisis-391275 \"“Bitcoin and Financial Crisis“ – Danny Bradbury\"\n[19]: https://www.cs.cornell.edu/home/rvr/papers/flowgossip.pdf \"“Efficient Reconciliation and Flow Control for Anti-Entropy Protocols“ – Robbert van Renesse\"\n","excerpt":"Le Bitcoin est l’une des premières cryptomonnaies utilisant un réseau de type paire-à-paire et des systèmes cryptographiques sophistiqués. Elle est…","tableOfContents":{"items":[{"url":"#les-origines-du-bitcoin","title":"Les origines du Bitcoin","items":[{"url":"#lauteur-du-bitcoin-satoshi-nakamoto","title":"L’auteur du Bitcoin: Satoshi Nakamoto"},{"url":"#la-reconnaissance-dans-le-monde","title":"La reconnaissance dans le monde"}]},{"url":"#point-de-vue-économique","title":"Point de vue économique","items":[{"url":"#les-débuts-du-bitcoin-sur-le-marché","title":"Les débuts du Bitcoin sur le marché"},{"url":"#comparaison-avec-les-monnaies-classiques","title":"Comparaison avec les monnaies classiques"}]},{"url":"#fonctionnement-et-réseau","title":"Fonctionnement et réseau","items":[{"url":"#blockchain","title":"Blockchain"},{"url":"#transactions","title":"Transactions"}]},{"url":"#resources","title":"Resources"}]},"fields":{"slug":"/blog/2018-03-05-bitcoin-origine-et-fonctionnement/","timeToRead":{"minutes":13.495,"words":2699}},"frontmatter":{"title":"Bitcoin – origine et fonctionnement","authors":["Bartosz Łaniewski","Tao Schreiner"],"keywords":["Blockchain","Cryptocurrency"],"language":"fr","description":null,"dateCreated":"March 04, 2018","dateCreatedMeta":"2018-03-05 00:00:00 +0100","dateUpdated":"December 25, 2023","dateUpdatedMeta":"2023-12-26 00:00:00 +0100","datePublished":"March 04, 2018","datePublishedMeta":"2018-03-05 00:00:00 +0100"},"internal":{"contentFilePath":"/home/runner/work/bartozzz.github.io/bartozzz.github.io/content/blog/2018-03-05-bitcoin-origine-et-fonctionnement/index.md"}},{"id":"3713577e-ecdb-5838-ad3c-dff0146689d3","body":"\nOdwiedzając strony internetowe, użytkownicy udzielają dostępu do unikalnych, tudzież prywatnych informacji. Te zaś pozwalają na precyzyjną identyfikację ich maszyn oraz inwigilację, bez konieczności rejestracji. Ten sposób śledzenia często opiera się o tzw. [Browser Fingerprint][1] — najczęściej spotykany i jednocześnie najtrudniejszy do wykrycia sposób rozpoznawania internautów na podstawie danych udostępnianych poprzez oprogramowanie.\n\n## Czym jest „Web Tracking”?\n\nTermin ten odnosi się do procesu generowania trwałego, unikalnego identyfikatora w celu rozpoznawania maszyn na podstawie „odcisku” przeglądarki oraz danych, które ta udostępnia na poziomie swojego <abbr title=\"od Application Programming Interface – interfejs programowania aplikacji\">API</abbr>. Do takich danych należą m.in. informacje dot. systemu operacyjnego, zainstalowanych rozszerzeń oraz komponentów maszyny użytkownika. Najprostsza implementacja takiego narzędzia śledzącego opiera się o ustandaryzowany [obiekt `navigator`][2]:\n\n```json\n{\n  \"appName\": \"Netscape\",\n  \"appCodeName\": \"Mozilla\",\n  \"appVersion\": \"Mozilla/5.0 (Macintosh … Gecko) Chrome/6…3 Safari/5…6\",\n  \"vendor\": \"Google Inc.\",\n  \"vendorSub\": \"\",\n  \"product\": \"Gecko\",\n  \"productSub\": \"20…00\",\n  \"platform\": \"MacIntel\",\n  \"deviceMemory\": 8,\n  \"hardwareConcurrency\": 4,\n  \"language\": \"en\",\n  \"languages\": [\"en\", \"pl\", \"fr\"],\n  \"plugins\": {},\n  \"cookieEnabled\": true\n}\n```\n\nBazując się na wyżej wymienionych informacjach, bardzo łatwo można wygenerować identyfikator, który posłuży do rozpoznawania niezalogowanego użytkownika na stronie szpiegującego. Jak wynika z badań doktora Peter Eckersley pt. [_„How Unique Is Your Web Browser?”_][3], na 400000 odwiedzin, ponad 80% użytkowników ma unikalne odciski.\n\n> 83.6% of the browsers seen had an instantaneously unique fingerprint, and a further 5.3% had an anonymity set of size 2. Among visiting browsers that had either Adobe Flash or a Java Virtual Machine enabled, 94.2% exhibited instantaneously unique fingerprints and a further 4.8% had fingerprints that were seen exactly twice. – Peter Eckersley\n\n### Jakie dane są wykorzystywane do rozpoznawania użytkownika?\n\n1.  **Adres IP** oraz <abbr title=\"od Internet service provider – dostawca usług internetowych\">ISP</abbr>: należy używać ostrożnie — dynamiczna alokacja adresów IP przez dostawców może być problematyczna. Z tego powodu, adresy IP są częściej używane do blokowania dostępu aniżeli identyfikacji maszyn.\n2.  **Ciasteczka**: najczęściej wykorzystywane przez narzędzia do analizy ruchu i dostawców reklam. Wraz z przepisami znowelizowanej ustawy [Prawa Telekomunikacyjnego][5] coraz więcej osób decyduje się jednak na ich blokowanie.\n3.  **Przeglądarka**: zgodnie ze specyfikacją [<abbr title=\"od Request for Comments – zbiór technicznych dokumentów związanych z Internetem\">RFC</abbr> 7231 (5.5.3)][6], nagłówek <abbr title=\"od Hypertext Transfer Protocol\">HTTP</abbr> `User-Agent` zawiera informacje pozwalające na rozpoznanie programu, z którego klient wykonał zapytanie.\n\n<Alert>\n\n  Przeglądarka Google Chrome [planuje zredukować](https://developers.google.com/privacy-sandbox/protections/user-agent informacje wysyłane w nagłówku HTTP `User-Agent` oraz w obiekcie `navigator`. Ma to na celu zredukowanie informacji służących do identyfikacji użytkowników na podstawie odcisku przeglądarki.\n</Alert>\n\n[Preferowane języki][7] użytkownika, [rozszerzenia][8], dostępne czcionki, wsparcie przeglądarki oraz reszta danych systemowych są również powszechnie przetwarzane. Pełną listę charakterystyk, wraz z technicznym opisem oraz metodami ich pozyskania można znaleźć w artykule [_„Technical analysis of client identification mechanisms”_][4] autorstwa Artura Janc i Michała Zalewskiego.\n\n### Jak wygląda „Web Tracking” pod maską?\n\nDo rozpoznawania użytkownika używa się algorytmu, który kolekcjonuje i przetwarza udostępnione przez przeglądarkę charakterystyki. Na ich podstawie jest wyliczany unikalny, stabilny identyfikator przypisany dla konkretnego klienta. Charakterystyki mogą być przesyłane na dwa sposoby – _statycznie_, poprzez zapytanie HTTP, oraz _dynamicznie_, poprzez <abbr title=\"od Asynchronous JavaScript and XML – asynchroniczny JavaScript i XML\">AJAX</abbr>.\n\nAJAX daje dostęp do większej ilości danych, ponieważ służy do pobierania charakterystyk bezpośrednio z API przeglądarki. Do takich informacji wliczamy listy [dostępnych czcionek][9], wtyczek, strefę czasową oraz rozdzielczość ekranu. Co więcej, wiele narzędzi posuwa się nawet do [śledzenie kliknięć oraz ruchów kursora][10]:\n\n> We divided the methods into several categories: explicitly assigned client-side identifiers, such as HTTP cookies; inherent client device characteristics that identify a particular machine; and **measurable user behaviors and preferences that may reveal the identity of the person** behind the keyboard (or touchscreen). – Artur Janc and Michal Zalewski\n\nZmienny adres IP, usuwanie danych przeglądania, aktualizacja oprogramowania, a nawet zmiana rozdzielczości ekranu może mieć znaczny wpływ na odcisk naszej przeglądarki, dlatego ważne jest, aby algorytm był stabilny i przygotowany na takie okoliczności. Przykładowa implementacja takiego algorytmu została opisana w sekcji 5.2. publikacji [„How Unique Is Your Web Browser?”][3] autorstwa Petera Eckersley.\n\n<Newsletter />\n\n## Jak się bronić przed „Browser Fingerprint”?\n\nParadoksalnie, stworzenie wtyczki, która zapobiegłaby identyfikacji naszej przeglądarki w sieci, niekoniecznie rozwiązałoby problem. Aby narzędzie było skutecznie, musiałoby z niego korzystać wystarczająco dużo użytkowników. W przeciwnym wypadku identyfikacja nadal będzie możliwa, lecz posłużą ku temu fałszywe dane dostarczone przez oprogramowanie.\n\nPoniższe rozszerzenia powinny jednak poradzić sobie z wieloma metodami śledzenia w sieci. Wszystkie są używane przez setki tysięcy ludzi na całym świecie, a kod źródłowy wtyczek jest całkowicie otwarty:\n\n1.  [`uBlock Origin`][11]: _„An efficient blocker: easy on memory and CPU footprint, and yet can load and enforce thousands more filters than other popular blockers.”_.\n2.  [`noscript`][12]: _„Provides extra protection: allows JavaScript, Java, Flash and other plugins to be executed only by trusted web sites of your choice.”_.\n3.  [`Blend In`][13]: _„Blends in OS-related values in User-Agent HTTP request header & a number of JS properties, so that Firefox (Thunderbird) appears to sites visited as running on the OS being used the most in the world.”_.\n4.  [`ClearURLs`][17]: _„Automatically removes tracking elements from URLs to help protect your privacy when browsing through the internet.”_.\n\nDodaj filtry z [`easylist` i `easyprivacy`][14]: _„The EasyList filter lists are sets of rules originally designed for Adblock that automatically remove unwanted content from the internet, including annoying adverts, bothersome banners and troublesome tracking.”_.\n\n[Zablokuj złośliwe strony w pliku `hosts`][15]: _„Extending and consolidating hosts files from several well-curated sources like adaway.org, mvps.org, malwaredomainlist.com, someonewhocares.org, and potentially others. You can optionally invoke extensions to block additional sites by category.”_.\n\n---\n\n## Źródła\n\n1.  [_„How Unique Is Your Web Browser?”_ – Peter Eckersley][3]\n2.  [_„Technical analysis of client identification mechanisms”_ - Artur Janc and Michal Zalewski][4]\n3.  [_„No Clicks, No Problem: Using Cursor Movements to Understand and Improve Search”_ – Jeff Huang, Ryen White and Susan Dumais][10]\n\n[1]: https://en.wikipedia.org/wiki/Device_fingerprint \"Device fingerprint – Wikipedia\"\n[2]: https://html.spec.whatwg.org/multipage/system-state.html#system-state-and-capabilities \"HTML Standard – The Navigator object\"\n[3]: https://coveryourtracks.eff.org/static/browser-uniqueness.pdf \"How Unique Is Your Web Browser? – Peter Eckersley\"\n[4]: https://www.chromium.org/Home/chromium-security/client-identification-mechanisms/ \"Technical analysis of client identification mechanisms – Artur Janc and Michal Zalewski\"\n[5]: https://www.dziennikustaw.gov.pl/DU/2012/1445 \"Ustawa z dnia 16 listopada 2012 r. o zmianie ustawy – Prawo telekomunikacyjne oraz niektórych innych ustaw\"\n[6]: https://tools.ietf.org/html/rfc7231#section-5.5.3 \"RFC 7231 – User-Agent\"\n[7]: https://html.spec.whatwg.org/multipage/webappapis.html \"W3C Recommendation – Language preferences\"\n[8]: https://html.spec.whatwg.org/multipage/system-state.html#plugins-2 \"HTML Standard – Plugins\"\n[9]: https://www.maratz.com/blog/archives/2006/08/18/detect-visitors-fonts-with-flash/ \"Detect visitor’s fonts with Flash – Marko Dugonjić\"\n[10]: https://www.microsoft.com/en-us/research/publication/no-clicks-no-problem-using-cursor-movements-to-understand-and-improve-search-2/ \"No Clicks, No Problem: Using Cursor Movements to Understand and Improve Search – Jeff Huang, Ryen White and Susan Dumais\"\n[11]: https://github.com/gorhill/uBlock\n[12]: https://noscript.net/\n[13]: https://addons.mozilla.org/en-US/firefox/addon/blend-in/\n[14]: https://easylist.to/\n[15]: https://github.com/StevenBlack/hosts\n[16]: https://rekseto.github.io/eksperymenty/inne/javascript/2018/06/04/jak-duzo-o-tobie-wiem.html\n[17]: https://docs.clearurls.xyz/\n\n\n","excerpt":"Odwiedzając strony internetowe, użytkownicy udzielają dostępu do unikalnych, tudzież prywatnych informacji. Te zaś pozwalają na precyzyjną identyfikację…","tableOfContents":{"items":[{"url":"#czym-jest-web-tracking","title":"Czym jest „Web Tracking”?","items":[{"url":"#jakie-dane-są-wykorzystywane-do-rozpoznawania-użytkownika","title":"Jakie dane są wykorzystywane do rozpoznawania użytkownika?"},{"url":"#jak-wygląda-web-tracking-pod-maską","title":"Jak wygląda „Web Tracking” pod maską?"}]},{"url":"#jak-się-bronić-przed-browser-fingerprint","title":"Jak się bronić przed „Browser Fingerprint”?"},{"url":"#źródła","title":"Źródła"}]},"fields":{"slug":"/blog/2018-02-18-identyfikacja-uzytkownika-na-podstawie-odcisku-przegladarki/","timeToRead":{"minutes":5.325,"words":1065}},"frontmatter":{"title":"Identyfikacja użytkownika na podstawie odcisku przeglądarki","authors":["Bartosz Łaniewski"],"keywords":["Security","Privacy"],"language":"pl","description":null,"dateCreated":"February 17, 2018","dateCreatedMeta":"2018-02-18 00:00:00 +0100","dateUpdated":"December 25, 2023","dateUpdatedMeta":"2023-12-26 00:00:00 +0100","datePublished":"February 17, 2018","datePublishedMeta":"2018-02-18 00:00:00 +0100"},"internal":{"contentFilePath":"/home/runner/work/bartozzz.github.io/bartozzz.github.io/content/blog/2018-02-18-identyfikacja-uzytkownika-na-podstawie-odcisku-przegladarki/index.md"}}]}},"staticQueryHashes":["1271460761","3216310583","991007626"],"slicesMap":{}}